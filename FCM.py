import streamlit as st
import pandas as pd
import requests
import json
import string
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="MCDM è«–æ–‡æº–å‰‡å®šå‘åˆ†æå™¨", layout="wide", page_icon="ğŸ¯")

# --- 2. å´é‚Šæ¬„ï¼šè¨­å®šå€ ---
with st.sidebar:
    st.header("ğŸ¯ ç ”ç©¶è¨­å®š")
    st.info("è«‹è¼¸å…¥æ‚¨çš„è«–æ–‡é¡Œç›®èˆ‡ç›®æ¨™æ•¸é‡ï¼ŒAI å°‡ç‚ºæ‚¨é‡èº«æ‰“é€ è©•ä¼°æº–å‰‡ã€‚")
    
    # API Key è¼¸å…¥
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    
    # æ–°å¢ï¼šè«–æ–‡é¡Œç›®è¼¸å…¥
    thesis_topic = st.text_input("æ‚¨çš„è«–æ–‡/ç ”ç©¶é¡Œç›®ï¼š", placeholder="ä¾‹å¦‚ï¼šé¤é£²æ¥­å°å…¥ AI æœå‹™ä¹‹è©•ä¼°æº–å‰‡ç ”ç©¶")
    
    # æ–°å¢ï¼šæŒ‡å®šæº–å‰‡æ•¸é‡
    criteria_count = st.number_input("å¸Œæœ›èƒå–çš„æº–å‰‡æ•¸é‡ï¼š", min_value=3, max_value=20, value=12, step=1)

# --- 3. è‡ªå‹•å°‹æ‰¾å¯ç”¨æ¨¡å‹ ---
def get_best_model(key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            for m in models:
                if 'gemini-1.5-pro' in m['name']: return m['name'] # å„ªå…ˆç”¨ Pro (æ¯”è¼ƒè°æ˜)
            for m in models:
                if 'gemini-1.5-flash' in m['name']: return m['name']
            for m in models:
                if 'gemini' in m['name']: return m['name']
        return "models/gemini-1.5-flash"
    except:
        return "models/gemini-1.5-flash"

# --- 4. æ ¸å¿ƒåˆ†æé‚è¼¯ (MCDM å®šå‘ Prompt) ---
def run_focused_mcdm(text, key, model_name, topic, count):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    # é€™æ˜¯æœ€å¼·çš„ MCDM å®šå‘æŒ‡ä»¤
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ MCDMï¼ˆå¤šæº–å‰‡æ±ºç­–åˆ†æï¼‰çš„ç ”ç©¶å°ˆå®¶ã€‚
    ã€ä½¿ç”¨è€…ç ”ç©¶é¡Œç›®ã€‘ï¼š{topic}
    ã€ç›®æ¨™ã€‘ï¼šè«‹å¾æä¾›çš„æ–‡ç»ä¸­ï¼Œæ­¸ç´å‡ºæœ€é©åˆè©²é¡Œç›®çš„ {count} å€‹è©•ä¼°æº–å‰‡ã€‚

    ã€ä»»å‹™æµç¨‹ã€‘ï¼š
    1. é–±è®€æ‰€æœ‰æ–‡ç»æ‘˜è¦ã€‚
    2. æ ¹æ“šã€Œç ”ç©¶é¡Œç›®ã€ï¼Œç¯©é¸å‡ºæœ€ç›¸é—œçš„ {count} å€‹è©•ä¼°æº–å‰‡ (Criteria)ã€‚æº–å‰‡å¿…é ˆæ˜¯åè©ï¼ˆå¦‚ï¼šå»ºç½®æˆæœ¬ã€å€‹è³‡å®‰å…¨æ€§ã€ä»‹é¢æ˜“ç”¨æ€§ï¼‰ã€‚
    3. æ•´ç†æ¯ä¸€ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼ã€‚
    4. å»ºç«‹å°ç…§é—œä¿‚ï¼šé€™ {count} å€‹æº–å‰‡åˆ†åˆ¥åœ¨å“ªå¹¾ç¯‡æ–‡ç»ä¸­è¢«æåˆ°ï¼Ÿ

    ã€è¼¸å‡ºæ ¼å¼ã€‘ï¼š
    è«‹ç›´æ¥å›å‚³ç´” JSON æ ¼å¼ (ä¸è¦ Markdown)ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
    {{
      "master_criteria": ["æº–å‰‡1", "æº–å‰‡2", ... "æº–å‰‡{count}"],
      "papers": [
        {{
          "apa": "ä½œè€… (å¹´ä»½). æ–‡ç»æ¨™é¡Œ...",
          "matched_criteria": ["æº–å‰‡1", "æº–å‰‡3"] 
        }},
        ...
      ]
    }}
    æ³¨æ„ï¼šmaster_criteria çš„æ•¸é‡å¿…é ˆç›¡é‡æ¥è¿‘ {count} å€‹ã€‚matched_criteria å¿…é ˆåªåŒ…å« master_criteria è£¡é¢çš„é …ç›®ã€‚

    ã€åŸå§‹æ–‡ç»è³‡æ–™ã€‘ï¼š
    {text[:13000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            clean_json = res_text.replace("```json", "").replace("```", "").strip()
            return "OK", json.loads(clean_json)
        else:
            return "ERROR", f"éŒ¯èª¤ ({response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢ ---
st.title("ğŸ¯ MCDM æº–å‰‡å®šå‘åˆ†æå·¥ä½œå€")

if not thesis_topic:
    st.warning("ğŸ‘ˆ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥æ‚¨çš„ã€Œè«–æ–‡é¡Œç›®ã€ï¼Œé€™æ¨£ AI æ‰èƒ½æŠ“å¾—æº–ï¼")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»æ‘˜è¦ï¼š", height=300)

if st.button("ğŸš€ é–‹å§‹åˆ†æ (ä¾ç…§é¡Œç›®èˆ‡æ•¸é‡)", type="primary"):
    if not api_key:
        st.error("âŒ è«‹å…ˆè²¼ä¸Š API Keyï¼")
    elif not thesis_topic:
        st.error("âŒ è«‹è¼¸å…¥è«–æ–‡é¡Œç›®ï¼")
    elif not raw_text:
        st.warning("âš ï¸ è«‹è¼¸å…¥æ–‡ç»è³‡æ–™ï¼")
    else:
        with st.spinner(f"ğŸ” AI æ­£åœ¨æ ¹æ“šé¡Œç›®ã€Œ{thesis_topic}ã€æ­¸ç´å‡º {criteria_count} å€‹æº–å‰‡..."):
            valid_model = get_best_model(api_key)
            
            # å‘¼å« AI
            status, result_data = run_focused_mcdm(raw_text, api_key, valid_model, thesis_topic, criteria_count)
            
            if status == "OK":
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # è§£æ JSON
                # result_data çµæ§‹: { "master_criteria": [...], "papers": [...] }
                
                try:
                    master_criteria = result_data.get("master_criteria", [])
                    papers = result_data.get("papers", [])
                    
                    if not master_criteria:
                        st.warning("AI æ²’èƒ½æŠ“åˆ°æº–å‰‡ï¼Œè«‹æª¢æŸ¥æ–‡ç»å…§å®¹æ˜¯å¦è¶³å¤ è±å¯Œã€‚")
                    else:
                        # 1. é¡¯ç¤º AI æŠ“åˆ°çš„ Master List
                        st.subheader(f"ğŸ¯ AI ç‚ºæ‚¨æ­¸ç´çš„ {len(master_criteria)} å€‹é—œéµæº–å‰‡")
                        final_criteria = st.multiselect("æ‚¨å¯ä»¥æ‰‹å‹•å¾®èª¿ (åˆªæ¸›)ï¼š", options=master_criteria, default=master_criteria)
                        
                        if final_criteria:
                            # 2. å»ºç«‹çŸ©é™£
                            matrix = {}
                            labels = []
                            apa_list = []
                            
                            for i, paper in enumerate(papers):
                                lbl = string.ascii_uppercase[i % 26]
                                labels.append(lbl)
                                apa_list.append(paper["apa"])
                                
                                # æª¢æŸ¥é€™ç¯‡è«–æ–‡æ˜¯å¦åŒ…å«é¸å®šçš„æº–å‰‡
                                paper_crits = paper.get("matched_criteria", [])
                                matrix[lbl] = ["â—" if c in paper_crits else "" for c in final_criteria]
                            
                            # 3. è½‰ DataFrame
                            df_matrix = pd.DataFrame(matrix, index=final_criteria)
                            df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "æ–‡ç»ä¾†æº (APA)": apa_list})
                            
                            st.divider()
                            
                            # 4. é¡¯ç¤ºçµæœ
                            c1, c2 = st.columns([1.5, 2.5])
                            with c1:
                                st.subheader("ğŸ“Š æº–å‰‡æª¢æ ¸çŸ©é™£")
                                st.dataframe(df_matrix, use_container_width=True)
                            with c2:
                                st.subheader("ğŸ“ æ–‡ç»å°ç…§è¡¨")
                                st.dataframe(df_legend, hide_index=True, use_container_width=True)
                            
                            # 5. ä¸‹è¼‰
                            output = BytesIO()
                            try:
                                import xlsxwriter
                                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                    df_matrix.to_excel(writer, sheet_name='MCDMçŸ©é™£')
                                    df_legend.to_excel(writer, sheet_name='æ–‡ç»ä¾†æº')
                                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨", output.getvalue(), "mcdm_thesis_analysis.xlsx", type="primary")
                            except:
                                st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", df_matrix.to_csv().encode('utf-8-sig'), "mcdm_analysis.csv")

                except Exception as parse_err:
                    st.error("è³‡æ–™è§£æéŒ¯èª¤ï¼Œå¯èƒ½æ˜¯ AI å›å‚³æ ¼å¼ä¸ç¬¦ã€‚è«‹é‡è©¦ä¸€æ¬¡ã€‚")
                    st.json(result_data)
            else:
                st.error("åˆ†æå¤±æ•—")
                st.code(result_data)
