import streamlit as st
import pandas as pd
import requests
import json
import string
import re
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="MCDM é›™éšæ®µåˆ†æ (è‡ªå‹•é©é…ç©©å®šç‰ˆ)", layout="wide", page_icon="ğŸ§¬")

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ§¬ è¨­å®š")
    st.info("æ­¤ç‰ˆæœ¬æœƒè‡ªå‹•åµæ¸¬æ‚¨çš„é‡‘é‘°æ¬Šé™ï¼Œå„ªå…ˆä½¿ç”¨å¯ç”¨çš„æ¨¡å‹ï¼Œé¿å… 404 éŒ¯èª¤ã€‚")
    
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    
    thesis_topic = st.text_input("è«–æ–‡é¡Œç›®ï¼š", value="é¤é£²æ¥­å°å…¥ AI æœå‹™ä¹‹è©•ä¼°æº–å‰‡")
    
    c1, c2 = st.columns(2)
    with c1:
        pool_size = st.number_input("Step 1 åŸå§‹æ•¸é‡", value=50)
    with c2:
        target_size = st.number_input("Step 2 æ”¶æ–‚æ•¸é‡", value=15)

# --- 3. æ ¸å¿ƒï¼šè‡ªå‹•å°‹æ‰¾å¯ç”¨çš„æ¨¡å‹ (ä¿®å¾© 404 çš„é—œéµ) ---
def get_best_model(key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            
            # 1. å…ˆæ‰¾ Flash (é€šå¸¸æœ€ç©©ï¼Œæ¬Šé™æœ€é–‹æ”¾)
            for m in models:
                if 'gemini-1.5-flash' in m['name']: return m['name']
            
            # 2. å¦‚æœæ²’æœ‰ï¼Œæ‰¾ Pro
            for m in models:
                if 'gemini-1.5-pro' in m['name']: return m['name']
            
            # 3. å†æ²’æœ‰ï¼Œæ‰¾ä»»ä½• Gemini
            for m in models:
                if 'gemini' in m['name'] and 'generateContent' in m.get('supportedGenerationMethods', []):
                    return m['name']
            
            return None # çœŸçš„æ‰¾ä¸åˆ°
        else:
            return None
    except:
        return None

# --- 4. åˆ†æé‚è¼¯ (å« JSON å¼·åŠ›æ¸…æ´—) ---
def run_two_stage_analysis(text, key, model_name, topic, pool_n, target_n):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ MCDM ç ”ç©¶å°ˆå®¶ã€‚ä½¿ç”¨è€…é¡Œç›®ï¼š{topic}ã€‚
    è«‹åŸ·è¡Œåš´æ ¼çš„ã€Œå…©éšæ®µæº–å‰‡ç¯©é¸ã€ï¼Œä¸¦å›å‚³ JSON è³‡æ–™ã€‚

    ã€ä»»å‹™ 1ï¼šå»ºç«‹æº–å‰‡æ±  (Pooling)ã€‘
    å¾æ–‡ç»ä¸­æ‰¾å‡ºç´„ {pool_n} å€‹ã€ŒåŸå§‹ç´°é …æº–å‰‡ (Raw Criteria)ã€ã€‚

    ã€ä»»å‹™ 2ï¼šæº–å‰‡æ”¶æ–‚ (Convergence)ã€‘
    å°‡ä¸Šè¿°åŸå§‹æº–å‰‡é€²è¡Œé‚è¼¯åˆ†é¡èˆ‡åˆä½µï¼Œæ­¸ç´å‡º {target_n} å€‹ã€Œæœ€çµ‚æ§‹é¢/æº–å‰‡ (Final Criteria)ã€ã€‚
    
    ã€é‡è¦ã€‘ï¼šåœ¨ "step2_convergence" ä¸­ï¼Œå¿…é ˆåŒ…å« "reasoning" æ¬„ä½ï¼Œè©³ç´°è§£é‡‹è©²æœ€çµ‚æº–å‰‡æ˜¯ç”±å“ªäº›åŸå§‹æº–å‰‡åˆä½µè€Œä¾†ï¼Œä»¥åŠåŸå› ã€‚

    ã€è¼¸å‡ºæ ¼å¼ (JSON Only)ã€‘ï¼š
    è«‹å‹™å¿…åªå›å‚³ JSONï¼Œä¸è¦æœ‰ markdown code blockã€‚
    {{
      "step1_raw_pool": [
        {{ "id": 1, "name": "åŸå§‹æº–å‰‡A" }},
        ... (ç´„ {pool_n} å€‹)
      ],
      "step2_convergence": [
        {{
          "id": 1,
          "final_name": "æœ€çµ‚æº–å‰‡åç¨±",
          "source_raw_items": ["åŸå§‹æº–å‰‡A", "åŸå§‹æº–å‰‡B"],
          "reasoning": "åˆä½µç†ç”±..."
        }},
        ... (ç´„ {target_n} å€‹)
      ]
    }}
    
    æ–‡ç»ï¼š
    {text[:13000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            try:
                res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            except:
                return "ERROR", "AI å›å‚³çµæ§‹ç•°å¸¸ã€‚"

            # å¼·åŠ›æ¸…æ´—ï¼šåªæŠ“å– { ... }
            match = re.search(r'\{.*\}', res_text, re.DOTALL)
            if match:
                clean_json_str = match.group(0)
                try:
                    return "OK", json.loads(clean_json_str)
                except json.JSONDecodeError as e:
                    return "ERROR", f"JSON è§£æå¤±æ•— (æ ¼å¼éŒ¯èª¤)ã€‚\nå…§å®¹ç‰‡æ®µ: {clean_json_str[:200]}"
            else:
                return "ERROR", f"æ‰¾ä¸åˆ° JSON çµæ§‹ã€‚\nAI å›å‚³: {res_text[:200]}"
        else:
            return "ERROR", f"API é€£ç·šéŒ¯èª¤ ({response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢ ---
st.title("ğŸ§¬ MCDM æº–å‰‡ï¼šé›™éšæ®µå ±å‘Šç”Ÿæˆ")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»æ‘˜è¦ï¼š", height=250)

if st.button("ğŸš€ åŸ·è¡Œé›™éšæ®µåˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹è¼¸å…¥ Key")
    elif not raw_text:
        st.warning("âš ï¸ è«‹è¼¸å…¥æ–‡ç»")
    else:
        with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•åµæ¸¬å¯ç”¨æ¨¡å‹ä¸¦åŸ·è¡Œåˆ†æ..."):
            
            # 1. è‡ªå‹•æ‰¾æ¨¡å‹ (é€™æ­¥æœ€é‡è¦)
            valid_model = get_best_model(api_key)
            
            if not valid_model:
                st.error("âŒ ç„¡æ³•æ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹ã€‚è«‹æª¢æŸ¥ Key æ˜¯å¦æ­£ç¢ºæˆ–æ¬Šé™æ˜¯å¦é–‹å•Ÿã€‚")
            else:
                st.success(f"âœ… é€£ç·šæˆåŠŸï¼è‡ªå‹•é¸ç”¨æ¨¡å‹ï¼š`{valid_model}`")
                
                # 2. åŸ·è¡Œåˆ†æ
                status, result = run_two_stage_analysis(raw_text, api_key, valid_model, thesis_topic, pool_size, target_size)
                
                if status == "OK":
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                    
                    tab1, tab2 = st.tabs(["ğŸ“‘ Step 1: åŸå§‹æº–å‰‡æ± ", "ğŸ¯ Step 2: æœ€çµ‚æ”¶æ–‚è¡¨"])
                    
                    # Tab 1
                    with tab1:
                        raw_data = result.get("step1_raw_pool", [])
                        if raw_data:
                            df_raw = pd.DataFrame(raw_data)
                            if "id" in df_raw.columns:
                                df_raw.rename(columns={"id": "åºè™Ÿ", "name": "åŸå§‹ç´°é …æº–å‰‡"}, inplace=True)
                            st.dataframe(df_raw, hide_index=True, use_container_width=True)

                    # Tab 2
                    with tab2:
                        conv_data = result.get("step2_convergence", [])
                        if conv_data:
                            rows = []
                            for item in conv_data:
                                row = {
                                    "åºè™Ÿ": item.get("id"),
                                    "æœ€çµ‚æº–å‰‡": item.get("final_name"),
                                    "æ¶µè“‹ä¹‹åŸå§‹ç´°é …": ", ".join(item.get("source_raw_items", [])),
                                    "æ”¶æ–‚é‚è¼¯/åŸå› ": item.get("reasoning")
                                }
                                rows.append(row)
                            
                            df_conv = pd.DataFrame(rows)
                            st.markdown("ğŸ‘‰ **æœ€å³é‚Šæœ‰è©³ç´°çš„æ”¶æ–‚åŸå› **")
                            st.dataframe(df_conv, hide_index=True, use_container_width=True)
                            
                            # ä¸‹è¼‰
                            output = BytesIO()
                            try:
                                import xlsxwriter
                                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                    if raw_data: df_raw.to_excel(writer, sheet_name='Step1_åŸå§‹', index=False)
                                    if conv_data: df_conv.to_excel(writer, sheet_name='Step2_æ”¶æ–‚', index=False)
                                st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Excel", output.getvalue(), "mcdm_final.xlsx", type="primary")
                            except:
                                st.error("Excel åŒ¯å‡ºå¤±æ•—")
                else:
                    st.error("åˆ†æå¤±æ•—ï¼ŒåŸå› å¦‚ä¸‹ï¼š")
                    st.code(result)
