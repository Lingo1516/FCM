import streamlit as st
import pandas as pd
import requests
import string
import re
from collections import Counter
from io import BytesIO

# --- å˜—è©¦åŒ¯å…¥å‚™ç”¨å¥—ä»¶ ---
try:
    import xlsxwriter
    import jieba
    import jieba.analyse
except ImportError:
    pass

# --- 1. è¨­å®š API Key (å·²å…§å»º) ---
USER_API_KEY = "AIzaSyBlj24gBVr3RJhkukS9p6yo5s2-WVBH2H0" 

# --- 2. é é¢è¨­å®š ---
st.set_page_config(page_title="AI æ–‡ç»åˆ†æ (åˆ†å·¥ç‰ˆ)", layout="wide", page_icon="ğŸ›ï¸")

# ==========================================
# ğŸ›‘ å·¦å´é‚Šæ¬„ï¼šè¨­å®šèˆ‡é€£ç·šæª¢æŸ¥ (é€™è£¡å…ˆåšï¼)
# ==========================================
with st.sidebar:
    st.header("ğŸ›ï¸ 1. æ¨¡å‹è¨­å®š")
    st.info("è«‹å…ˆåœ¨æ­¤é¸æ“‡æ¨¡å‹ï¼Œç¢ºèªé€£ç·šæˆåŠŸå¾Œï¼Œå†åˆ°å³é‚Šè²¼è³‡æ–™ã€‚")
    
    # è®“ä½¿ç”¨è€…é¸æ“‡è¦ç”¨å“ªä¸€å€‹ç‰ˆæœ¬
    model_option = st.radio(
        "è«‹é¸æ“‡ AI ç‰ˆæœ¬ï¼š",
        ("Gemini 1.5 Flash (å¿«é€Ÿ/æ–°ç‰ˆ)", "Gemini Pro (ç©©å®š/èˆŠç‰ˆ)", "æœ¬æ©Ÿæ¼”ç®—æ³• (å‚™ç”¨/ç„¡é¡åº¦é™åˆ¶)")
    )
    
    st.divider()
    st.subheader("ğŸ“¡ é€£ç·šç‹€æ…‹")
    
    # æ ¹æ“šé¸æ“‡çš„æ¨¡å‹å®šç¾© API ç¶²å€
    target_model_name = ""
    if "Flash" in model_option:
        target_model_name = "gemini-1.5-flash"
    elif "Pro" in model_option:
        target_model_name = "gemini-pro"
    
    # è‡ªå‹•æ¸¬è©¦é€£ç·šé‚è¼¯
    connection_status = st.empty() # ä½”ä½ç¬¦
    
    if "æœ¬æ©Ÿ" in model_option:
        connection_status.success("âœ… æœ¬æ©Ÿæ¨¡å¼ï¼šéš¨æ™‚å¯ç”¨ (ç„¡éœ€é€£ç¶²)")
        active_mode = "LOCAL"
    else:
        # æ¸¬è©¦æŒ‰éˆ•
        if st.button("æŒ‰æ­¤æ¸¬è©¦é€£ç·š"):
            with st.spinner("é€£ç·šæª¢æŸ¥ä¸­..."):
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model_name}:generateContent?key={USER_API_KEY}"
                    headers = {'Content-Type': 'application/json'}
                    data = {"contents": [{"parts": [{"text": "Hi"}]}]}
                    resp = requests.post(url, headers=headers, json=data)
                    
                    if resp.status_code == 200:
                        connection_status.success(f"âœ… é€£ç·šæˆåŠŸï¼\n({target_model_name})")
                        active_mode = "GOOGLE"
                    elif resp.status_code == 429:
                        connection_status.error("âŒ é¡åº¦æ»¿äº† (429)")
                        active_mode = "QUOTA_FULL"
                    else:
                        connection_status.error(f"âŒ å¤±æ•—: {resp.status_code}")
                        active_mode = "ERROR"
                except Exception as e:
                    connection_status.error("âŒ ç¶²çµ¡éŒ¯èª¤")
                    active_mode = "ERROR"
        else:
            connection_status.warning("âš ï¸ è«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•æ¸¬è©¦")
            active_mode = "GOOGLE" # é è¨­å…ˆçµ¦éï¼Œç­‰ä¸‹åŸ·è¡Œå†æ“‹

# ==========================================
# ğŸ‘‰ å³å´ä¸»ç•«é¢ï¼šè¼¸å…¥èˆ‡åˆ†æ
# ==========================================
st.title("ğŸ“„ æ–‡ç»åˆ†æå·¥ä½œå€")
st.markdown(f"**ç›®å‰é¸æ“‡æ¨¡å¼ï¼š** `{model_option}`")

# è¼¸å…¥å€
raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šè³‡æ–™ (æ¯ç¯‡è«‹æ›è¡Œ)ï¼š", height=250, placeholder="è³‡æ–™è¼¸å…¥å€...")

# --- å‡½æ•¸å€ ---

def run_google_analysis(text, model_name):
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={USER_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    prompt = f"ä»»å‹™ï¼šæ­¸ç´ 10 å€‹å­¸è¡“ç ”ç©¶æ§‹é¢é—œéµå­—ã€‚è¦å‰‡ï¼šåªåˆ—å‡ºåè©ï¼Œç”¨é “è™Ÿéš”é–‹ã€‚æ’é™¤ç„¡é—œè©å½™(å¦‚æ—¥æœŸã€ä¸‹åˆ)ã€‚å…§å®¹ï¼š{text[:5000]}"
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return None
    except:
        return None

def run_local_analysis(text):
    try:
        return jieba.analyse.extract_tags(text, topK=15, allowPOS=('n', 'vn', 'v'))
    except:
        clean = re.sub(r'[^\u4e00-\u9fa5]', '', text)
        words = [clean[i:i+2] for i in range(len(clean)-1)]
        return [w for w, c in Counter(words).most_common(15)]

def parse_text(text):
    lines = text.strip().split('\n')
    return [{"title": line[:15], "content": line} for line in lines if len(line) > 5]

# --- åŸ·è¡ŒæŒ‰éˆ• ---
if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè¼¸å…¥è³‡æ–™ï¼")
    else:
        st.divider()
        result_text = None
        keywords = []
        
        # æ ¹æ“šå·¦é‚Šçš„è¨­å®šä¾†è·‘
        if "æœ¬æ©Ÿ" in model_option:
            with st.spinner("æ­£åœ¨ä½¿ç”¨æœ¬æ©Ÿæ¼”ç®—æ³•è¨ˆç®—..."):
                keywords = run_local_analysis(raw_text)
                st.success("âœ… æœ¬æ©Ÿåˆ†æå®Œæˆ")
        else:
            # Google æ¨¡å¼
            with st.spinner(f"æ­£åœ¨å‘¼å« {target_model_name} ..."):
                ai_res = run_google_analysis(raw_text, target_model_name)
                if ai_res:
                    st.success("âœ… AI åˆ†æå®Œæˆ")
                    keywords = [k.strip() for k in ai_res.replace("\n", "ã€").split("ã€") if k.strip()]
                else:
                    st.error("âŒ AI é€£ç·šå¤±æ•—æˆ–é¡åº¦å·²æ»¿ï¼Œè‡ªå‹•åˆ‡æ›è‡³æœ¬æ©Ÿæ¼”ç®—æ³•æ•‘æ´...")
                    keywords = run_local_analysis(raw_text)

        # --- é¡¯ç¤ºçµæœ (å…±ç”¨) ---
        if keywords:
            # ç¯©é¸å™¨
            final_keywords = st.multiselect("åˆ†ææº–å‰‡ (å¯èª¿æ•´)", options=keywords, default=keywords)
            
            if final_keywords:
                lit_data = parse_text(raw_text)
                matrix = {}
                labels = []
                titles = []
                
                for i, item in enumerate(lit_data):
                    lbl = string.ascii_uppercase[i % 26]
                    labels.append(lbl)
                    titles.append(item['title'])
                    col_res = ["â—‹" if k in item['content'] else "" for k in final_keywords]
                    matrix[lbl] = col_res
                
                df = pd.DataFrame(matrix, index=final_keywords)
                df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "æ–‡ç»": titles})
                
                c1, c2 = st.columns([2, 1])
                with c1: st.dataframe(df, use_container_width=True)
                with c2: st.dataframe(df_legend, hide_index=True)
                
                # ä¸‹è¼‰
                output = BytesIO()
                try:
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, sheet_name='çŸ©é™£')
                        df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "analysis.xlsx")
                except:
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", df.to_csv().encode('utf-8-sig'), "analysis.csv")
