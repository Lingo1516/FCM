import streamlit as st
import pandas as pd
import requests
import json
import string
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="AI æ–‡ç»åˆ†æ (APA å®Œç¾ç‰ˆ)", layout="wide", page_icon="ğŸ“")

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    st.info("æ­¤ç‰ˆæœ¬æœƒè‡ªå‹•å°‡æ‚¨çš„æ–‡ç»è½‰ç‚º APA æ ¼å¼ï¼Œä¸å†æœƒå› ç‚ºæ›è¡Œè€Œåˆ‡ç¢ã€‚")
    api_key = st.text_input("Google API Key", type="password")

# --- 3. è‡ªå‹•å°‹æ‰¾å¯ç”¨æ¨¡å‹ ---
def get_best_model(key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            for m in models:
                if 'gemini-1.5-flash' in m['name']: return m['name']
            for m in models:
                if 'gemini-1.5-pro' in m['name']: return m['name']
            for m in models:
                if 'gemini' in m['name'] and 'generateContent' in m.get('supportedGenerationMethods', []):
                    return m['name']
        return "models/gemini-1.5-flash" # é è¨­ fallback
    except:
        return "models/gemini-1.5-flash"

# --- 4. æ ¸å¿ƒåˆ†æé‚è¼¯ (æ”¹ç”¨ JSON å¼·åˆ¶çµæ§‹åŒ–) ---
def run_smart_analysis(text, key, model_name):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    # é€™æ˜¯æœ€å¼·çš„ Promptï¼šè¦æ±‚ AI ç›´æ¥å›å‚³æ•´ç†å¥½çš„ JSON
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å­¸è¡“åˆ†æå°ˆå®¶ã€‚è«‹é–±è®€ä»¥ä¸‹é›œäº‚çš„æ–‡ç»åŸå§‹è³‡æ–™ï¼ˆå¯èƒ½åŒ…å«ä¸€ç¯‡æˆ–å¤šç¯‡ï¼‰ã€‚
    è«‹å¹«æˆ‘åšå…©ä»¶äº‹ï¼š
    1. è¾¨è­˜å‡ºæœ‰å¹¾ç¯‡ä¸åŒçš„æ–‡ç»ï¼Œå°‡æ¯ä¸€ç¯‡æ•´ç†æˆã€ŒAPA å¼•ç”¨æ ¼å¼ (ä½œè€…, å¹´ä»½, æ¨™é¡Œ)ã€ã€‚
    2. é‡å°æ¯ä¸€ç¯‡æ–‡ç»ï¼Œåˆ†æå‡º 5-10 å€‹ã€Œç ”ç©¶æ§‹é¢ã€é—œéµå­—(åè©)ã€‚
    
    è«‹å‹™å¿…å›å‚³ç´” JSON æ ¼å¼ï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    [
      {{
        "apa": "é™³å°æ˜ (2024). é¤é£²æ¥­çš„æœå‹™å‰µæ–°ç ”ç©¶...",
        "keywords": ["æœå‹™å‰µæ–°", "æ»¿æ„åº¦", "å¿ èª åº¦"]
      }},
      {{
        "apa": "ç‹å¤§è¯ (2023). ...",
        "keywords": ["å•†æ¥­æ¨¡å¼", "SWOT", ...]
      }}
    ]

    åŸå§‹è³‡æ–™ï¼š
    {text[:10000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            # æ¸…ç†å¯èƒ½çš„å›å‚³é›œè¨Š (æœ‰äº›æ¨¡å‹æœƒåŠ  ```json )
            clean_json = res_text.replace("```json", "").replace("```", "").strip()
            return "OK", json.loads(clean_json)
        else:
            return "ERROR", f"éŒ¯èª¤ ({response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢èˆ‡åŸ·è¡Œ ---
st.title("ğŸ“„ æ–‡ç»åˆ†æå·¥ä½œå€ (APA è‡ªå‹•æ•´ç†)")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»è³‡æ–™ (äº‚ä¸€é»æ²’é—œä¿‚ï¼ŒAI æœƒè‡ªå·±æ•´ç†)ï¼š", height=300)

if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹å…ˆè²¼ä¸Š API Keyï¼")
    elif not raw_text:
        st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥æ–‡ç»è³‡æ–™ï¼")
    else:
        with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•é¸æ“‡æ¨¡å‹ä¸¦æ•´ç†æ–‡ç»..."):
            valid_model = get_best_model(api_key)
            
            # é–‹å§‹ AI åˆ†æ
            status, result_data = run_smart_analysis(raw_text, api_key, valid_model)
            
            if status == "OK":
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # result_data æ˜¯ä¸€å€‹ List [ {"apa":..., "keywords":...}, ... ]
                
                # 1. æ”¶é›†æ‰€æœ‰å‡ºç¾éçš„é—œéµå­— (å–è¯é›†)
                all_keywords = set()
                for paper in result_data:
                    for k in paper.get("keywords", []):
                        all_keywords.add(k)
                
                sorted_keywords = sorted(list(all_keywords))
                
                # 2. è®“ä½¿ç”¨è€…ç¯©é¸é—œéµå­—
                st.subheader("1ï¸âƒ£ ç¯©é¸åˆ†ææ§‹é¢")
                final_keywords = st.multiselect("è«‹å‹¾é¸è¦ä¿ç•™çš„æ§‹é¢ï¼š", options=sorted_keywords, default=sorted_keywords)
                
                if final_keywords:
                    # 3. å»ºç«‹çŸ©é™£
                    matrix = {}
                    labels = []
                    apa_list = []
                    
                    for i, paper in enumerate(result_data):
                        lbl = string.ascii_uppercase[i % 26]
                        labels.append(lbl)
                        # é€™è£¡å°±æ˜¯ä½ è¦çš„ï¼šå³é‚Šæ¬„ä½ç›´æ¥é¡¯ç¤º APA æ ¼å¼
                        apa_list.append(paper["apa"]) 
                        
                        # æª¢æŸ¥è©²ç¯‡è«–æ–‡çš„é—œéµå­—æ¸…å–®
                        paper_keywords = paper.get("keywords", [])
                        matrix[lbl] = ["â—" if k in paper_keywords else "" for k in final_keywords]
                    
                    # 4. é¡¯ç¤ºçµæœ
                    df_matrix = pd.DataFrame(matrix, index=final_keywords)
                    df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "APA æ–‡ç»ä¾†æº": apa_list})
                    
                    st.divider()
                    c1, c2 = st.columns([1.5, 2]) # èª¿æ•´æ¯”ä¾‹ï¼Œè®“å³é‚Šå¯¬ä¸€é»é¡¯ç¤º APA
                    with c1: 
                        st.subheader("ğŸ“Š åˆ†æçŸ©é™£")
                        st.dataframe(df_matrix, use_container_width=True)
                    with c2: 
                        st.subheader("ğŸ“ æ–‡ç»å°ç…§è¡¨ (APA)")
                        st.dataframe(df_legend, hide_index=True, use_container_width=True)
                    
                    # 5. ä¸‹è¼‰
                    output = BytesIO()
                    try:
                        import xlsxwriter
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            df_matrix.to_excel(writer, sheet_name='çŸ©é™£')
                            df_legend.to_excel(writer, sheet_name='APAä¾†æºè¡¨')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "analysis.xlsx")
                    except:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", df_matrix.to_csv().encode('utf-8-sig'), "analysis.csv")
            else:
                st.error("åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥ API Key æˆ–é‡è©¦ã€‚")
                st.code(result_data)
