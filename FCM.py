import streamlit as st
import pandas as pd
import requests
import string
import re
import time
from collections import Counter
from io import BytesIO

# --- å˜—è©¦åŒ¯å…¥å‚™ç”¨å¥—ä»¶ ---
try:
    import xlsxwriter
    import jieba
    import jieba.analyse
except ImportError:
    pass

# --- 1. è¨­å®š API Key ---
USER_API_KEY = "AIzaSyBlj24gBVr3RJhkukS9p6yo5s2-WVBH2H0" 

# --- 2. é é¢è¨­å®š ---
st.set_page_config(page_title="AI æ¨¡å‹æ·±åº¦å¥æª¢", layout="wide", page_icon="ğŸ©º")

if 'working_models' not in st.session_state:
    st.session_state.working_models = []
if 'scan_performed' not in st.session_state:
    st.session_state.scan_performed = False

# ==========================================
# ğŸ›‘ å·¦å´é‚Šæ¬„ï¼šæ·±åº¦å¥æª¢ç«™
# ==========================================
with st.sidebar:
    st.header("ğŸ©º ç¬¬ä¸€æ­¥ï¼šæ¨¡å‹å¥æª¢")
    st.info("é€™å€‹æŒ‰éˆ•æœƒå¯¦éš›æ¸¬è©¦æ¯å€‹æ¨¡å‹ï¼Œéæ¿¾æ‰ã€Œé¡åº¦å·²æ»¿ã€çš„å£æ¨¡å‹ã€‚")
    
    # æ¸¬è©¦å‡½æ•¸
    def check_model_health(key, model_name):
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
        headers = {'Content-Type': 'application/json'}
        # å‚³é€ä¸€å€‹æ¥µçŸ­çš„å­—ç¬¦ä¾†æ¸¬è©¦
        data = {"contents": [{"parts": [{"text": "Hi"}]}]}
        try:
            response = requests.post(url, headers=headers, json=data, timeout=5)
            if response.status_code == 200:
                return True # æ´»è‘—
            else:
                return False # æ­»æ‰ (429 æˆ–å…¶ä»–)
        except:
            return False

    # æ·±åº¦æƒææŒ‰éˆ•
    if st.button("ğŸš€ åŸ·è¡Œæ·±åº¦æƒæ (åªç•™æ´»å£)", type="primary"):
        st.session_state.working_models = [] # æ¸…ç©ºèˆŠç´€éŒ„
        
        # æˆ‘å€‘åªæ¸¬è©¦é€™å¹¾å€‹æœ€å¸¸ç”¨ä¸”å¯èƒ½æœ‰é¡åº¦çš„ (é¿å…æ¸¬è©¦å¤ªå¤šå°è‡´è‡ªå·±è¢«é–)
        target_candidates = [
            "gemini-1.5-flash",
            "gemini-1.5-pro",
            "gemini-2.0-flash",     # æ–°ç‰ˆ
            "gemini-2.0-flash-lite-preview-02-05", # è¼•é‡ç‰ˆ(é€šå¸¸æ¯”è¼ƒç©º)
            "gemini-1.0-pro"        # èˆŠç‰ˆ(å‚™ç”¨)
        ]
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        found_any = False
        
        for i, model in enumerate(target_candidates):
            status_text.text(f"æ­£åœ¨æ¸¬è©¦ï¼š{model} ...")
            
            # å¯¦éš›æ‰“ä¸€æ¬¡ API
            is_healthy = check_model_health(USER_API_KEY, model)
            
            if is_healthy:
                st.session_state.working_models.append(model)
                st.toast(f"âœ… {model} æ¸¬è©¦é€šéï¼")
                found_any = True
            else:
                # å¤±æ•—å°±ä¸åŠ å…¥æ¸…å–®
                print(f"{model} æ¸¬è©¦å¤±æ•—")
            
            # æ›´æ–°é€²åº¦æ¢
            progress_bar.progress((i + 1) / len(target_candidates))
            time.sleep(0.5) # ç¨å¾®åœé “ä¸€ä¸‹ï¼Œé¿å…è¢«åˆ¤å®šæ”»æ“Š
            
        st.session_state.scan_performed = True
        status_text.text("æƒæå®Œæˆï¼")
        
        if not found_any:
            st.error("âŒ æ‰€æœ‰ Google æ¨¡å‹éƒ½å¿™ç·šä¸­ (429)ã€‚å»ºè­°ä½¿ç”¨æœ¬æ©Ÿæ¨¡å¼ã€‚")

    st.divider()
    
    # é¡¯ç¤ºã€Œç¶“éç¯©é¸ã€çš„é¸å–®
    final_selection = None
    
    if st.session_state.scan_performed:
        if st.session_state.working_models:
            st.success(f"âœ… æ‰¾åˆ° {len(st.session_state.working_models)} å€‹å¯ç”¨æ¨¡å‹ï¼")
            final_selection = st.radio(
                "è«‹é¸æ“‡ä¸€å€‹ (é€™äº›éƒ½æ˜¯ç¢ºå®šèƒ½ç”¨çš„)ï¼š",
                st.session_state.working_models
            )
        else:
            st.warning("âš ï¸ Google å…¨ç·šå´©æ½°ï¼Œå·²è‡ªå‹•åˆ‡æ›è‡³ã€Œæœ¬æ©Ÿå‚™ç”¨æ¨¡å¼ã€ã€‚")
            final_selection = "Local (æœ¬æ©Ÿå‚™ç”¨)"
    else:
        st.markdown("ç­‰å¾…æƒæä¸­...")

# ==========================================
# ğŸ‘‰ å³å´ä¸»ç•«é¢
# ==========================================
st.title("ğŸ“„ æ–‡ç»åˆ†æå·¥ä½œå€ (å¥æª¢ç‰ˆ)")

if not st.session_state.scan_performed:
    st.info("â¬…ï¸ è«‹å…ˆåœ¨å·¦å´é»æ“Š **ã€ŒğŸš€ åŸ·è¡Œæ·±åº¦æƒæã€**ã€‚")
    st.markdown("""
    **ç‚ºä»€éº¼è¦é€™éº¼åšï¼Ÿ**
    å…ˆå‰çš„æƒæåªæ˜¯åˆ—å‡ºåå­—ï¼Œæ²’æœ‰æª¢æŸ¥é¡åº¦ã€‚
    é€™æ¬¡æˆ‘å€‘æœƒçœŸçš„å»ã€Œæ•²é–€ã€ï¼Œç¢ºèªå°æ–¹æœ‰ç©ºæ‰è®“ä½ é¸ï¼Œé¿å…ä½ ç™½å¿™ä¸€å ´ã€‚
    """)
else:
    # é¡¯ç¤ºè¼¸å…¥æ¡†
    st.success(f"ğŸš€ ç•¶å‰ä½¿ç”¨æ ¸å¿ƒï¼š**{final_selection}**")
    
    raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»è³‡æ–™ (æ¯ç¯‡è«‹æ›è¡Œ)ï¼š", height=300)

    # åˆ†æå‡½æ•¸
    def run_analysis_smart(text, model_name):
        if model_name == "Local (æœ¬æ©Ÿå‚™ç”¨)":
            try:
                return jieba.analyse.extract_tags(text, topK=15, allowPOS=('n', 'vn', 'v'))
            except:
                clean = re.sub(r'[^\u4e00-\u9fa5]', '', text)
                words = [clean[i:i+2] for i in range(len(clean)-1)]
                return [w for w, c in Counter(words).most_common(15)]
        
        # Google æ¨¡å¼
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={USER_API_KEY}"
        headers = {'Content-Type': 'application/json'}
        prompt = f"ä»»å‹™ï¼šæ­¸ç´ 10 å€‹å­¸è¡“ç ”ç©¶æ§‹é¢é—œéµå­—ã€‚è¦å‰‡ï¼šåªåˆ—å‡ºåè©ï¼Œç”¨é “è™Ÿéš”é–‹ã€‚æ’é™¤ç„¡é—œè©å½™(å¦‚æ—¥æœŸã€ä¸‹åˆ)ã€‚å…§å®¹ï¼š{text[:5000]}"
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                return response.json()['candidates'][0]['content']['parts'][0]['text']
            else:
                return None
        except:
            return None

    def parse_text(text):
        lines = text.strip().split('\n')
        return [{"title": line[:15], "content": line} for line in lines if len(line) > 5]

    if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
        if not raw_text:
            st.warning("è«‹å…ˆè¼¸å…¥è³‡æ–™ï¼")
        else:
            keywords = []
            with st.spinner(f"æ­£åœ¨åˆ†æ..."):
                res = run_analysis_smart(raw_text, final_selection)
                
                if isinstance(res, str):
                    keywords = [k.strip() for k in res.replace("\n", "ã€").split("ã€") if k.strip()]
                    st.success("âœ… åˆ†ææˆåŠŸ")
                elif isinstance(res, list):
                    keywords = res
                    st.success("âœ… æœ¬æ©Ÿé‹ç®—æˆåŠŸ")
                else:
                    st.error("âŒ å“å‘€ï¼Œå‰›æ¸¬éèƒ½ç”¨ï¼Œçµæœç¾åœ¨åˆæ»¿äº†ã€‚è«‹é‡è©¦ä¸€æ¬¡æˆ–åˆ‡æ›æ¨¡å‹ã€‚")

            if keywords:
                final_keywords = st.multiselect("åˆ†ææº–å‰‡", options=keywords, default=keywords)
                if final_keywords:
                    lit_data = parse_text(raw_text)
                    matrix = {}
                    labels = []
                    titles = []
                    for i, item in enumerate(lit_data):
                        lbl = string.ascii_uppercase[i % 26]
                        labels.append(lbl)
                        titles.append(item['title'])
                        matrix[lbl] = ["â—‹" if k in item['content'] else "" for k in final_keywords]
                    
                    df = pd.DataFrame(matrix, index=final_keywords)
                    df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "æ–‡ç»": titles})
                    
                    c1, c2 = st.columns([2, 1])
                    with c1: st.dataframe(df, use_container_width=True)
                    with c2: st.dataframe(df_legend, hide_index=True)
                    
                    output = BytesIO()
                    try:
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            df.to_excel(writer, sheet_name='çŸ©é™£')
                            df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "analysis.xlsx")
                    except:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", df.to_csv().encode('utf-8-sig'), "analysis.csv")
