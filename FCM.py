import streamlit as st
import pandas as pd
import requests
import string
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="å­¸è¡“æ–‡ç»åˆ†æå™¨ (æ­£å¼ç‰ˆ)", layout="wide", page_icon="ğŸ“")

# --- 2. å´é‚Šæ¬„ï¼šè¨­å®šé‘°åŒ™ ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    st.info("è«‹è²¼ä¸Šå‰›å‰›è¨ºæ–·é€šéçš„é‚£æŠŠé‘°åŒ™ (çµå°¾æ˜¯ WY0iw)")
    
    # è®“ä½¿ç”¨è€…è²¼ä¸Š Key
    api_key = st.text_input("Google API Key", type="password")
    
    # æ¨¡å‹é¸æ“‡ (é è¨­ç”¨æœ€ç©©çš„ Flash)
    model_name = st.selectbox("é¸æ“‡æ¨¡å‹", ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-1.0-pro"])

# --- 3. ä¸»ç•«é¢ ---
st.title("ğŸ“„ å­¸è¡“æ–‡ç»åˆ†æå·¥ä½œå€")

# è¼¸å…¥å€
raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»è³‡æ–™ (æ¯ç¯‡è«‹æ›è¡Œ)ï¼š", height=300, placeholder="è²¼ä¸Šä½ çš„è«–æ–‡æ‘˜è¦...")

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---
def run_analysis(text, key, model):
    # é€™æ˜¯å‰›å‰›è¨ºæ–·é€šéçš„é€£ç·šæ–¹å¼
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä»»å‹™ï¼šæ­¸ç´ 10 åˆ° 15 å€‹æœ€é‡è¦çš„ã€Œç ”ç©¶æ§‹é¢ã€æˆ–ã€Œè©•ä¼°æº–å‰‡ã€ã€‚
    è¦å‰‡ï¼š
    1. åªè¼¸å‡ºåè© (ä¾‹å¦‚ï¼šæ»¿æ„åº¦ã€ç²åˆ©èƒ½åŠ›)ã€‚
    2. ç”¨é “è™Ÿã€Œã€ã€éš”é–‹ã€‚
    3. åš´æ ¼æ’é™¤ï¼šæ—¥æœŸã€ä¸‹åˆã€ä½œè€…åã€å ±å‘Šã€ç ”ç©¶æ–¹æ³•ã€‚
    
    å…§å®¹ï¼š
    {text[:8000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return "OK", response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return "ERROR", f"é€£ç·šéŒ¯èª¤ (ä»£ç¢¼ {response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

def parse_literature(text):
    lines = text.strip().split('\n')
    return [{"title": line[:15] + "..." if len(line)>15 else line, "content": line} for line in lines if len(line) > 5]

# --- 5. åŸ·è¡ŒæŒ‰éˆ• (ä¿®å¾©äº†è·³å›åŸç•«é¢çš„å•é¡Œ) ---
if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹å…ˆåœ¨å·¦å´è²¼ä¸Š API Keyï¼")
    elif not raw_text:
        st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥æ–‡ç»è³‡æ–™ï¼")
    else:
        with st.spinner("ğŸ¤– AI æ­£åœ¨é–±è®€æ–‡ç»..."):
            status, result = run_analysis(raw_text, api_key, model_name)
            
            if status == "OK":
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # A. è™•ç†é—œéµå­—
                keywords = [k.strip() for k in result.replace("\n", "ã€").split("ã€") if k.strip()]
                
                # B. è®“ä½¿ç”¨è€…ç¯©é¸
                st.subheader("1ï¸âƒ£ AI å»ºè­°çš„æ§‹é¢")
                final_keywords = st.multiselect("è«‹å‹¾é¸è¦ä¿ç•™çš„é …ç›®ï¼š", options=keywords, default=keywords)
                
                if final_keywords:
                    # C. å»ºç«‹çŸ©é™£
                    lit_data = parse_literature(raw_text)
                    matrix = {}
                    labels = []
                    titles = []
                    
                    for i, item in enumerate(lit_data):
                        lbl = string.ascii_uppercase[i % 26]
                        labels.append(lbl)
                        titles.append(item['title'])
                        # åˆ¤æ–·è©²æ–‡ç»æ˜¯å¦åŒ…å«è©²é—œéµå­—
                        matrix[lbl] = ["â—" if k in item['content'] else "" for k in final_keywords]
                    
                    # D. é¡¯ç¤ºçµæœ
                    df_matrix = pd.DataFrame(matrix, index=final_keywords)
                    df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "æ–‡ç»æ¨™é¡Œ": titles})
                    
                    st.divider()
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.subheader("ğŸ“Š åˆ†æçŸ©é™£")
                        st.dataframe(df_matrix, use_container_width=True)
                        
                    with col2:
                        st.subheader("ğŸ“ æ–‡ç»å°ç…§è¡¨")
                        st.dataframe(df_legend, hide_index=True, use_container_width=True)
                    
                    # E. ä¸‹è¼‰æŒ‰éˆ•
                    output = BytesIO()
                    try:
                        import xlsxwriter
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            df_matrix.to_excel(writer, sheet_name='åˆ†æçŸ©é™£')
                            df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                        file_name = "ai_analysis_result.xlsx"
                        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    except ImportError:
                        # å‚™ç”¨ CSV
                        output.write(df_matrix.to_csv().encode('utf-8-sig'))
                        file_name = "ai_analysis_result.csv"
                        mime_type = "text/csv"
                        
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è¼‰å ±è¡¨ ({file_name})",
                        data=output.getvalue(),
                        file_name=file_name,
                        mime=mime_type,
                        type="primary"
                    )
            else:
                st.error(result)
