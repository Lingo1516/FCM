import streamlit as st
import pandas as pd
import string
from collections import Counter
from io import BytesIO
import re

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¬èƒ½æ–‡ç»çŸ©é™£ç”Ÿæˆå™¨", layout="wide", page_icon="ğŸ›¡ï¸")

st.title("ğŸ›¡ï¸ è¬èƒ½æ–‡ç»çŸ©é™£ç”Ÿæˆå™¨ (å®¹éŒ¯ç‰ˆ)")
st.markdown("""
### è§£æ±ºç„¡æ³•è¾¨è­˜çš„å•é¡Œï¼š
* **ä¸å†å¼·åˆ¶è¦æ±‚å¹´ä»½**ï¼šåªè¦ä½ çš„è³‡æ–™æœ‰ **ã€Œæ›è¡Œã€**ï¼Œç¨‹å¼å°±æœƒè‡ªå‹•åˆ‡åˆ†ã€‚
* **è‡ªå‹•æŠ“å–é—œéµå­—**ï¼šé‹ç”¨çµ±è¨ˆåŸç†ï¼Œè‡ªå‹•æ‰¾å‡ºå‡ºç¾æœ€å¤šæ¬¡çš„è©ã€‚
""")

# --- 1. è¼¸å…¥å€ ---
st.info("ğŸ‘‡ è«‹å°‡æ–‡ç»è³‡æ–™è²¼åœ¨ä¸‹æ–¹ (è«‹ç¢ºä¿æ¯ä¸€ç¯‡æ–‡ç»éƒ½åœ¨ **æ–°çš„ä¸€è¡Œ**)")
raw_text = st.text_area("æ–‡ç»è³‡æ–™è¼¸å…¥å€ï¼š", height=250, placeholder="ä¾‹å¦‚ï¼š\nç¬¬ä¸€ç¯‡æ–‡ç»çš„æ‘˜è¦å…§å®¹...\nç¬¬äºŒç¯‡é—œæ–¼ç¸¾æ•ˆç®¡ç†çš„å…§å®¹...\nç¬¬ä¸‰ç¯‡è¨è«–å“¡å·¥æ»¿æ„åº¦çš„...")

# --- 2. æ ¸å¿ƒé‚è¼¯ï¼šæœ€ç°¡å–®æš´åŠ›çš„åˆ‡å‰²æ³• ---
def loose_parse(text):
    # ç›´æ¥ç”¨ã€Œæ›è¡Œç¬¦è™Ÿã€ä¾†åˆ‡å‰²ï¼Œä¸ç®¡å…§å®¹æ˜¯ä»€éº¼
    lines = text.strip().split('\n')
    
    literature_list = []
    
    for line in lines:
        line = line.strip()
        if len(line) < 5: continue # éæ¿¾æ‰å¤ªçŸ­çš„å»¢è©±æˆ–ç©ºè¡Œ
        
        # å˜—è©¦è‡ªå‹•æŠ“ä¸€å€‹ã€Œæ¨™é¡Œã€æˆ–ã€Œä½œè€…ã€çµ¦å®ƒ
        # é‚è¼¯ï¼šå–é€™è¡Œæ–‡å­—çš„å‰ 15 å€‹å­—ç•¶ä½œä»£è™Ÿåç¨±
        author_guess = line[:15] + "..." if len(line) > 15 else line
        
        literature_list.append({
            "author": author_guess, # é€™æ˜¯çµ¦å°ç…§è¡¨ç”¨çš„åç¨±
            "abstract": line        # é€™æ˜¯è¦æ‹¿ä¾†åˆ†æçš„å…§å®¹
        })
        
    return literature_list

# --- 3. å…å®‰è£é—œéµå­—çµ±è¨ˆ (N-gram) ---
def simple_keyword_extraction(text_list, top_n=20):
    # æŠŠæ‰€æœ‰æ–‡ç»ä¸²åœ¨ä¸€èµ·åˆ†æ
    full_text = " ".join([item['abstract'] for item in text_list])
    
    # åªä¿ç•™ä¸­æ–‡ (è®“çµ±è¨ˆæ›´æº–)
    chinese_only = re.sub(r'[^\u4e00-\u9fa5]', '', full_text)
    
    words = []
    # æ’é™¤å¸¸è¦‹ç„¡æ„ç¾©è©å½™
    stopwords = set(['ç ”ç©¶', 'æ¢è¨', 'åˆ†æ', 'çµæœ', 'é¡¯ç¤º', 'ç™¼ç¾', 'æå‡º', 'èªç‚º', 'ä½¿ç”¨', 'é€²è¡Œ', 'å½±éŸ¿', 'æˆ‘å€‘', 'é€™äº›', 'ä¸åŒ', 'ä»¥åŠ', 'é€é', 'å°æ–¼', 'æ–‡ç»', 'æœ¬æ–‡'])

    # æŠ“å– 2~4 å€‹å­—çš„è©
    for i in range(len(chinese_only)):
        # 2å­—è©
        if i + 2 <= len(chinese_only):
            w = chinese_only[i:i+2]
            if w not in stopwords: words.append(w)
        # 3å­—è©
        if i + 3 <= len(chinese_only):
            w = chinese_only[i:i+3]
            if w not in stopwords: words.append(w)
        # 4å­—è©
        if i + 4 <= len(chinese_only):
            w = chinese_only[i:i+4]
            if w not in stopwords: words.append(w)
            
    # çµ±è¨ˆé »ç‡
    counter = Counter(words)
    # å–å‡ºå‰ N å€‹é«˜é »è©
    most_common = [w for w, c in counter.most_common(top_n)]
    return most_common

# --- 4. åŸ·è¡ŒæŒ‰éˆ• ---
col_action, col_manual = st.columns([1, 2])

with col_action:
    run_btn = st.button("ğŸš€ å¼·åˆ¶åˆ†æ", type="primary", help="ä¸ç®¡æ ¼å¼å°ä¸å°ï¼ŒæŒ‰ä¸‹å»å°±å°äº†")

# é€™è£¡é ç•™ä¸€å€‹ Session State å­˜é—œéµå­—ï¼Œä»¥å…é‡æ•´å¾Œä¸è¦‹
if 'auto_keywords' not in st.session_state:
    st.session_state.auto_keywords = []

if run_btn and raw_text:
    # 1. åˆ‡å‰²æ–‡ç»
    lit_data = loose_parse(raw_text)
    
    if not lit_data:
        st.error("âŒ ç„¡æ³•åˆ‡å‰²è³‡æ–™ã€‚è«‹ç¢ºèªä½ æœ‰è²¼ä¸Šæ–‡å­—ï¼Œè€Œä¸”æœ‰æŒ‰ Enter æ›è¡Œã€‚")
    else:
        st.success(f"âœ… æˆåŠŸåˆ‡åˆ†å‡º {len(lit_data)} ç­†è³‡æ–™ï¼")
        
        # 2. æŠ“é—œéµå­—
        st.session_state.auto_keywords = simple_keyword_extraction(lit_data)

# --- 5. çµæœé¡¯ç¤ºèˆ‡ç¯©é¸ ---
if st.session_state.auto_keywords:
    
    st.divider()
    st.subheader("1ï¸âƒ£ ç¢ºèªåˆ†ææº–å‰‡ (é—œéµå­—)")
    
    # è®“ä½¿ç”¨è€…å¯ä»¥è‡ªå·±åŠ é—œéµå­—ï¼é€™å¾ˆé‡è¦ï¼Œå› ç‚ºè‡ªå‹•æŠ“çš„ä¸ä¸€å®šæº–
    user_added = st.text_input("æƒ³è¦æ‰‹å‹•å¢åŠ é—œéµå­—å—ï¼Ÿ(ç”¨ç©ºç™½éš”é–‹)", placeholder="ä¾‹å¦‚ï¼šESG æ•¸ä½è½‰å‹")
    
    # åˆä½µè‡ªå‹•æŠ“çš„ + æ‰‹å‹•åŠ çš„
    all_options = st.session_state.auto_keywords
    if user_added:
        extras = user_added.split()
        all_options = extras + all_options
    
    final_keywords = st.multiselect(
        "è«‹å‹¾é¸æ‚¨è¦é¡¯ç¤ºåœ¨è¡¨æ ¼å·¦å´çš„æº–å‰‡ï¼š",
        options=all_options,
        default=all_options[:10] # é è¨­åªé¸å‰10å€‹é¿å…è¡¨æ ¼å¤ªå¤§
    )
    
    if final_keywords:
        # 3. é‡æ–°åˆ‡å‰²ä¸€æ¬¡ä»¥ç¢ºä¿è³‡æ–™æœ€æ–° (æˆ–ç›´æ¥ç”¨ä¸Šé¢çš„ lit_data è‹¥æƒ³å„ªåŒ–æ•ˆèƒ½)
        lit_data = loose_parse(raw_text)
        
        # 4. è£½ä½œçŸ©é™£
        matrix = {}
        labels = []
        full_names = []
        
        # ç”Ÿæˆä»£è™Ÿ A, B, C...
        def get_label(index):
            if index < 26: return string.ascii_uppercase[index]
            else: return f"{string.ascii_uppercase[index // 26 - 1]}{string.ascii_uppercase[index % 26]}"

        for i, item in enumerate(lit_data):
            label = get_label(i)
            labels.append(label)
            full_names.append(item['author']) # å°ç…§è¡¨ç”¨çš„å®Œæ•´åç¨±
            
            # æ¯”å°
            col_res = []
            for kw in final_keywords:
                if kw in item['abstract']:
                    col_res.append("â—‹") # ç¬¦åˆä½ çš„åœ–ç‰‡æ ¼å¼
                else:
                    col_res.append("")
            matrix[label] = col_res
            
        # è½‰ DataFrame
        df_matrix = pd.DataFrame(matrix, index=final_keywords)
        df_matrix.index.name = "æ§‹é¢\\æº–å‰‡"
        
        df_legend = pd.DataFrame({
            "æ–‡ç»æ¨™ç±¤": labels,
            "å°æ‡‰å…§å®¹ (å‰15å­—)": full_names
        })
        
        # --- é¡¯ç¤ºæœ€çµ‚çµæœ (æ¨¡ä»¿ä½ çš„æˆªåœ–) ---
        st.divider()
        st.subheader("2ï¸âƒ£ åˆ†æçµæœçŸ©é™£")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("##### é‡æ–°æ•´ç†å¾Œçš„è¡¨æ ¼æ ¼å¼ï¼š")
            st.dataframe(df_matrix, use_container_width=True)
            
        with col2:
            st.markdown("##### æœ€åº•éƒ¨çš„ä½œè€…å°æ‡‰è¡¨ï¼š")
            st.dataframe(df_legend, hide_index=True, use_container_width=True)
            
        # --- ä¸‹è¼‰ ---
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_matrix.to_excel(writer, sheet_name='çŸ©é™£åˆ†æ')
            df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
            
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰ Excel æª”æ¡ˆ", 
            data=output.getvalue(), 
            file_name="analysis_result.xlsx", 
            type="primary"
        )
