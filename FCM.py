import streamlit as st
import pandas as pd
import requests # æ”¹ç”¨é€™å€‹æœ€åŸºç¤çš„å¥—ä»¶
import json
import string
from io import BytesIO

# --- å˜—è©¦åŒ¯å…¥ xlsxwriter (é˜²å‘†) ---
try:
    import xlsxwriter
except ImportError:
    pass # æ²’è£å°±ç®—äº†ï¼Œå¾Œé¢æœ‰é˜²å‘†

# --- 1. è¨­å®šæ‚¨çš„ API Key ---
# âš ï¸ è«‹åœ¨ä¸‹æ–¹å¼•è™Ÿå…§è²¼ä¸Šä½ çš„ AIza é–‹é ­é‡‘é‘°
USER_API_KEY = "AIzaSyBlj24gBVr3RJhkukS9p6yo5s2-WVBH2H0" 

# --- 2. é é¢è¨­å®š ---
st.set_page_config(page_title="AI æ–‡ç»åˆ†æå™¨ (APIç›´é€£ç‰ˆ)", layout="wide", page_icon="âš¡")
st.title("âš¡ AI æ–‡ç»åˆ†æå™¨ (ç›´é€£ç‰ˆ)")
st.markdown("### ä½¿ç”¨ API ç›´é€£æ¨¡å¼ï¼Œç¹éå¥—ä»¶ç‰ˆæœ¬å•é¡Œ")

# --- 3. æ¸¬è©¦é€£ç·šæŒ‰éˆ• ---
if st.button("ğŸ“¡ æ¸¬è©¦ API é€£ç·š"):
    if "AIza" not in USER_API_KEY:
        st.error("âŒ é‡‘é‘°æ ¼å¼éŒ¯èª¤ï¼")
    else:
        with st.spinner("æ­£åœ¨ç›´é€£ Google ä¸»æ©Ÿ..."):
            try:
                # ç›´æ¥å‘¼å«ç¶²å€ï¼Œä¸é€éå¥—ä»¶
                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={USER_API_KEY}"
                headers = {'Content-Type': 'application/json'}
                data = {"contents": [{"parts": [{"text": "Hello"}]}]}
                
                response = requests.post(url, headers=headers, json=data)
                
                if response.status_code == 200:
                    st.success(f"âœ… é€£ç·šæˆåŠŸï¼Google å›æ‡‰ï¼š{response.json()['candidates'][0]['content']['parts'][0]['text']}")
                else:
                    st.error(f"âŒ é€£ç·šå¤±æ•— (ä»£ç¢¼ {response.status_code}): {response.text}")
            except Exception as e:
                st.error(f"âŒ ç¶²è·¯éŒ¯èª¤ï¼š{str(e)}")

# --- 4. æ–‡ç»è¼¸å…¥èˆ‡è™•ç† ---
st.info("ğŸ‘‡ è«‹è²¼ä¸Šæ–‡ç»è³‡æ–™ (æ¯ç¯‡è«‹æ›è¡Œ)")
raw_text = st.text_area("æ–‡ç»è¼¸å…¥å€", height=200)

def get_ai_analysis_via_api(text, key):
    # ä½¿ç”¨ REST API ç›´æ¥å‘¼å«ï¼Œä¸éœ€è¦ google-generativeai å¥—ä»¶
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä»»å‹™ï¼šæ­¸ç´ 10 å€‹å­¸è¡“ç ”ç©¶æ§‹é¢é—œéµå­—ã€‚
    è¦å‰‡ï¼šåªåˆ—å‡ºåè©ï¼Œç”¨é “è™Ÿéš”é–‹ã€‚æ’é™¤ç„¡é—œè©å½™(å¦‚æ—¥æœŸã€ä¸‹åˆ)ã€‚
    å…§å®¹ï¼š{text[:8000]}
    """
    
    data = {
        "contents": [{
            "parts": [{"text": prompt}]
        }]
    }
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            result = response.json()
            # è§£æè¤‡é›œçš„ JSON çµæ§‹
            return result['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"Error: {response.text}"
    except Exception as e:
        return f"Error: {str(e)}"

# åˆ‡å‰²æ–‡å­—é‚è¼¯
def parse_text(text):
    lines = text.strip().split('\n')
    return [{"title": line[:15], "content": line} for line in lines if len(line) > 5]

# --- 5. åŸ·è¡Œåˆ†æ ---
if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè²¼ä¸Šè³‡æ–™ï¼")
    else:
        with st.spinner("ğŸ¤– AI (ç›´é€£æ¨¡å¼) åˆ†æä¸­..."):
            lit_data = parse_text(raw_text)
            ai_result = get_ai_analysis_via_api(raw_text, USER_API_KEY)
            
            if "Error" in ai_result:
                st.error(f"åˆ†æå¤±æ•—ï¼š{ai_result}")
            else:
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # è™•ç†é—œéµå­—
                keywords = [k.strip() for k in ai_result.replace("\n", "ã€").split("ã€") if k.strip()]
                final_keywords = st.multiselect("AI æŠ“åˆ°çš„æº–å‰‡", options=keywords, default=keywords)
                
                if final_keywords:
                    # å»ºè¡¨
                    matrix = {}
                    labels = []
                    titles = []
                    for i, item in enumerate(lit_data):
                        lbl = string.ascii_uppercase[i % 26]
                        labels.append(lbl)
                        titles.append(item['title'])
                        col_res = []
                        for kw in final_keywords:
                            if kw in item['content']: col_res.append("â—‹")
                            else: col_res.append("")
                        matrix[lbl] = col_res
                    
                    # é¡¯ç¤º
                    df = pd.DataFrame(matrix, index=final_keywords)
                    df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "å°æ‡‰æ–‡ç»": titles})
                    
                    c1, c2 = st.columns([2, 1])
                    with c1: st.dataframe(df, use_container_width=True)
                    with c2: st.dataframe(df_legend, hide_index=True)
                    
                    # ä¸‹è¼‰ Excel
                    output = BytesIO()
                    try:
                        import xlsxwriter
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            df.to_excel(writer, sheet_name='çŸ©é™£')
                            df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "analysis.xlsx")
                    except ImportError:
                        # è¬ä¸€é€£ xlsxwriter éƒ½æ²’è£æˆåŠŸï¼Œè‡³å°‘çµ¦ CSV
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV (Excelç„¡æ³•ç”¨)", df.to_csv().encode('utf-8-sig'), "analysis.csv")
