import streamlit as st
import pandas as pd
import re
import string
from io import BytesIO

# å˜—è©¦åŒ¯å…¥çµå·´æ–·è© (ä¸­æ–‡åˆ†æå°ˆç”¨)
try:
    import jieba
    import jieba.analyse
except ImportError:
    st.error("è«‹å…ˆå®‰è£ jieba å¥—ä»¶: pip install jieba")
    st.stop()

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI çµ±è¨ˆåˆ†ææ–‡ç»å·¥å…·", layout="wide", page_icon="ğŸ§®")

st.title("ğŸ§® æ™ºæ…§çµ±è¨ˆæ–‡ç»åˆ†æå™¨ (æ¼”ç®—æ³•ç‰ˆ)")
st.markdown("""
### åŸç†èªªæ˜
é€™å€‹ç‰ˆæœ¬ä¸ä½¿ç”¨é è¨­å­—åº«ï¼Œä¹Ÿä¸éœ€è¦ AI Keyã€‚
å®ƒä½¿ç”¨ **TF-IDF æ¼”ç®—æ³•**ï¼Œç¾å ´è¨ˆç®—æ‚¨è²¼ä¸Šçš„æ–‡å­—ä¸­ï¼Œå“ªäº›è©å½™çš„**æ¬Šé‡æœ€é«˜**ï¼Œè‡ªå‹•æŠ“å‡ºä¾†ç•¶ä½œåˆ†ææº–å‰‡ã€‚
""")

# --- 1. è¼¸å…¥å€ ---
st.info("ğŸ’¡ è«‹è²¼ä¸Šæ‚¨çš„æ–‡ç»è³‡æ–™ï¼Œç³»çµ±æœƒè‡ªå‹•ç®—å‡ºæœ€å¸¸å‡ºç¾çš„é—œéµå­—ã€‚")
raw_text = st.text_area("æ–‡ç»è³‡æ–™è¼¸å…¥å€ï¼š", height=300, placeholder="ç›´æ¥æŠŠæ•´ç¯‡è«–æ–‡æ‘˜è¦æˆ–ç­†è¨˜è²¼é€²ä¾†...")

# --- 2. æ ¸å¿ƒé‚è¼¯ ---

def analyze_data(text):
    # æ­¥é©Ÿ A: åˆ‡å‰²æ–‡ç» (æŠ“å¹´ä»½)
    pattern = r'([^\n\rã€‚]+?[\(\[\{](?:19|20)\d{2}[\)\]\}])'
    segments = re.split(pattern, text)
    
    literature_list = []
    current_author = None
    all_abstracts_text = "" # ç”¨ä¾†çµ¦æ¼”ç®—æ³•åˆ†æçš„å¤§æ± å­
    
    for segment in segments:
        segment = segment.strip()
        if not segment: continue
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºä½œè€… (åŒ…å«å¹´ä»½)
        if re.search(r'[\(\[\{](?:19|20)\d{2}[\)\]\}]', segment):
            current_author = segment[-50:] # æˆªæ–·éé•·çš„èª¤åˆ¤
        else:
            # é€™æ˜¯æ‘˜è¦å…§å®¹
            if current_author:
                literature_list.append({"author": current_author, "abstract": segment})
                all_abstracts_text += segment + "\n" # ç´¯ç©æ‰€æœ‰æ‘˜è¦æ–‡å­—

    # æ­¥é©Ÿ B: ä½¿ç”¨ Jieba æ¼”ç®—æ³•æŠ“é—œéµå­—
    if not all_abstracts_text:
        return None, None

    # ä½¿ç”¨ extract_tags (åŸºæ–¼ TF-IDF æ¼”ç®—æ³•) æŠ“å–å‰ 20 å€‹é—œéµè©
    # allowPOS æŒ‡å®šè©æ€§ï¼šn=åè©, v=å‹•è©, vn=åå‹•è© (éæ¿¾æ‰ 'çš„', 'æ˜¯' é€™ç¨®å»¢è©±)
    keywords = jieba.analyse.extract_tags(all_abstracts_text, topK=20, allowPOS=('n', 'vn', 'v'))
    
    return literature_list, keywords

# --- 3. æ“ä½œä»‹é¢ ---

if st.button("ğŸš€ é–‹å§‹é‹ç®—èˆ‡åˆ†æ", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè²¼ä¸Šè³‡æ–™ï¼")
    else:
        with st.spinner("æ­£åœ¨é€²è¡Œæ–·è©èˆ‡æ¬Šé‡è¨ˆç®—..."):
            lit_data, auto_keywords = analyze_data(raw_text)
        
        if not lit_data:
            st.error("ç„¡æ³•è¾¨è­˜æ–‡ç»æ ¼å¼ï¼Œè«‹ç¢ºèªå…§å®¹åŒ…å«å¹´ä»½ (ä¾‹å¦‚: 2023)ã€‚")
        else:
            # --- é¡¯ç¤ºè‡ªå‹•æŠ“åˆ°çš„é—œéµå­— ---
            st.success(f"âœ… åˆ†æå®Œæˆï¼æ¼”ç®—æ³•ç®—å‡ºé€™ç¯‡æ–‡ç« æœ€é‡è¦çš„ {len(auto_keywords)} å€‹è©ï¼š")
            
            # è®“ä½¿ç”¨è€…å¯ä»¥åˆªæ¸›
            final_keywords = st.multiselect(
                "ç³»çµ±è‡ªå‹•æŠ“åˆ°çš„é—œéµå­— (æ‚¨å¯ä»¥åˆªé™¤ä¸å–œæ­¡çš„)",
                options=auto_keywords,
                default=auto_keywords
            )
            
            if not final_keywords:
                st.warning("è«‹è‡³å°‘ä¿ç•™ä¸€å€‹é—œéµå­—ä»¥ç”Ÿæˆåœ–è¡¨ã€‚")
            else:
                # --- ç”ŸæˆçŸ©é™£ ---
                matrix = {}
                labels = []
                authors = []
                
                # ç”Ÿæˆä»£è™Ÿ
                def get_label(index):
                    if index < 26: return string.ascii_uppercase[index]
                    else: return f"{string.ascii_uppercase[index // 26 - 1]}{string.ascii_uppercase[index % 26]}"

                for i, item in enumerate(lit_data):
                    label = get_label(i)
                    labels.append(label)
                    authors.append(item['author'])
                    
                    col_res = []
                    for kw in final_keywords:
                        if kw in item['abstract']:
                            col_res.append("â—")
                        else:
                            col_res.append("")
                    matrix[label] = col_res
                
                # --- é¡¯ç¤ºè¡¨æ ¼ ---
                df_matrix = pd.DataFrame(matrix, index=final_keywords)
                df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "ä½œè€…": authors})
                
                st.divider()
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.subheader("ğŸ“Š é—œéµå­—åˆ†æçŸ©é™£")
                    st.dataframe(df_matrix, use_container_width=True, height=500)
                
                with col2:
                    st.subheader("ğŸ“ æ–‡ç»å°ç…§è¡¨")
                    st.dataframe(df_legend, hide_index=True, use_container_width=True)
                
                # --- ä¸‹è¼‰ ---
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df_matrix.to_excel(writer, sheet_name='çŸ©é™£åˆ†æ')
                    df_legend.to_excel(writer, sheet_name='æ–‡ç»å°ç…§')
                
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨", output.getvalue(), "analysis_report.xlsx")
