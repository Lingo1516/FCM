import streamlit as st
from groq import Groq
import google.generativeai as genai
import time
import pandas as pd

# --- ç³»çµ±è¨­å®š ---
st.set_page_config(page_title="è«–æ–‡å¯«ä½œåŠ©æ‰‹ (å®‰å…¨ç„¡è­¦å ±ç‰ˆ)", layout="wide", page_icon="ğŸ›¡ï¸")

# --- å´é‚Šæ¬„ï¼šå¼•æ“èˆ‡é‡‘é‘°è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ å¼•æ“è¨­å®š")
    
    # é¸æ“‡å¼•æ“
    engine_choice = st.radio("é¸æ“‡ AI æ¨¡å‹", ["Groq (Llama 3)", "Google (Gemini)"])
    
    api_key = ""
    if engine_choice == "Groq (Llama 3)":
        st.info("æ¨è–¦ï¼é€Ÿåº¦å¿«ï¼Œé©åˆè™•ç†å¤§é‡æ–‡å­—ã€‚")
        # â¬‡ï¸ é€™è£¡æ”¹ç‚ºç©ºå­—ä¸²ï¼Œé¿å…è§¸ç™¼ Secret Scanning è­¦å‘Š
        api_key = st.text_input("è«‹è¼¸å…¥ Groq Key (gsk_...)", type="password")
        st.markdown("[ğŸ‘‰ é»æ­¤å…è²»ç”³è«‹ Groq Key](https://console.groq.com/keys)")
    else:
        st.info("å‚™ç”¨ã€‚Google å¼•æ“ã€‚")
        api_key = st.text_input("è«‹è¼¸å…¥ Google Key", type="password")
        st.markdown("[ğŸ‘‰ é»æ­¤å…è²»ç”³è«‹ Google Key](https://aistudio.google.com/app/apikey)")

    st.divider()

    # é—œéµå­—
    business_keywords = ["ç­–ç•¥ç®¡ç†", "ESG", "CSR", "æ¶ˆè²»è€…è¡Œç‚º", "æ»¿æ„åº¦", "ä¾›æ‡‰éˆ", "FinTech", "æ•¸ä½è½‰å‹"]
    selected_kws = st.multiselect("é¸æ“‡é—œéµå­—ï¼š", business_keywords)
    custom_kw = st.text_input("è‡ªè¨‚é—œéµå­—ï¼š")
    final_kws = selected_kws + ([custom_kw] if custom_kw else [])
    keywords_str = ", ".join(final_kws)

    # æ–¹æ³•
    method_category = st.selectbox("æ–¹æ³•åˆ†é¡", ["MCDM", "é‡åŒ–", "è³ªæ€§", "æ··åˆ"])
    final_method = method_category
    if "MCDM" in method_category:
        mcdm_tools = st.multiselect("å·¥å…·ï¼š", 
            ["Delphi", "Fuzzy Delphi", "AHP", "Fuzzy AHP", "ANP", "FCM (æ¨¡ç³ŠèªçŸ¥åœ–)", "TOPSIS"],
            default=["Delphi", "FCM (æ¨¡ç³ŠèªçŸ¥åœ–)"]
        )
        final_method = f"MCDM ({' + '.join(mcdm_tools)})" if mcdm_tools else "MCDM"

    # æ ¼å¼
    paper_type = st.radio("é¡å‹", ["å­¸ä½è«–æ–‡", "æœŸåˆŠè«–æ–‡"])
    if paper_type == "å­¸ä½è«–æ–‡":
        CHAPTERS = [
            {"key": "ch1", "name": "ç¬¬ä¸€ç«  ç·’è«–"},
            {"key": "ch2", "name": "ç¬¬äºŒç«  æ–‡ç»æ¢è¨"},
            {"key": "ch3", "name": "ç¬¬ä¸‰ç«  ç ”ç©¶æ–¹æ³•"},
            {"key": "ch4", "name": "ç¬¬å››ç«  åˆ†æçµæœ"},
            {"key": "ch5", "name": "ç¬¬äº”ç«  çµè«–"}
        ]
    else:
        CHAPTERS = [{"key": f"ch{i}", "name": n} for i, n in enumerate(["å‰è¨€", "æ–‡ç»", "æ–¹æ³•", "çµæœ", "çµè«–"], 1)]
    
    # è¦å‰‡
    if 'global_rules' not in st.session_state: 
        st.session_state.global_rules = "1. å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡\n2. æ•¸å­¸å…¬å¼èˆ‡æ¨¡å‹å¿…é ˆå®Œæ•´\n3. æ•¸æ“šçµæœå¿…é ˆå¼•ç”¨æ–‡ç»ä½è­‰"
    rules = st.text_area("å¯«ä½œè¦å‰‡", value=st.session_state.global_rules, height=100)
    st.session_state.global_rules = rules

# --- æ ¸å¿ƒå‡½æ•¸ï¼šå‘¼å« AI ---
def call_ai_api(prompt, sys_role="ä½ æ˜¯ä¸€ä½å­¸è¡“å°ˆå®¶ã€‚"):
    if not api_key:
        return "âš ï¸ è«‹åœ¨å·¦å´è¼¸å…¥ API Key æ‰èƒ½é–‹å§‹é‹ä½œã€‚"

    try:
        if engine_choice == "Groq (Llama 3)":
            client = Groq(api_key=api_key)
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": sys_role},
                    {"role": "user", "content": prompt}
                ],
                model="llama-3.3-70b-versatile",
                temperature=0.5,
                max_tokens=4000,
            )
            return completion.choices[0].message.content

        elif engine_choice == "Google (Gemini)":
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(
                f"{sys_role}\n\n{prompt}",
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4000,
                    temperature=0.5
                )
            )
            return response.text

    except Exception as e:
        error_msg = str(e)
        if "413" in error_msg:
            return "âŒ éŒ¯èª¤ 413ï¼šå…§å®¹å¤ªé•·ï¼è«‹ä½¿ç”¨ä¸‹æ–¹çš„ã€Œåˆ†æ‰¹è§£æã€ã€‚"
        elif "429" in error_msg:
            return "âŒ éŒ¯èª¤ 429ï¼šé¡åº¦å·²æ»¿ï¼Œè«‹æ›´æ› Keyã€‚"
        else:
            return f"âŒ é€£ç·šéŒ¯èª¤: {error_msg}"

# --- æ ¸å¿ƒå‡½æ•¸ï¼šæ™ºæ…§åˆ†æ‰¹è™•ç† ---
def smart_batch_process(long_text, method_name):
    if not api_key: return "âš ï¸ è«‹å…ˆè¼¸å…¥ API Key"
    
    chunk_size = 3000
    chunks = [long_text[i:i+chunk_size] for i in range(0, len(long_text), chunk_size)]
    total_chunks = len(chunks)
    
    progress_bar = st.progress(0, text="æº–å‚™é–‹å§‹åˆ†æ‰¹é–±è®€...")
    combined_notes = ""
    
    for i, chunk in enumerate(chunks):
        progress_bar.progress((i / total_chunks) * 0.8, text=f"æ­£åœ¨ç ”è®€ç¬¬ {i+1}/{total_chunks} éƒ¨åˆ†...")
        prompt = f"é€™æ˜¯ä¸€ä»½æ–‡ç»å›é¡§çš„ä¸€éƒ¨åˆ†ã€‚è«‹æå–ï¼š1.å­¸è€…å¹´ä»½ 2.è®Šæ•¸ 3.èˆ‡{method_name}çš„é—œè¯ã€‚\næ–‡ç»ç‰‡æ®µï¼š\n{chunk}"
        note = call_ai_api(prompt, sys_role="ä½ æ˜¯ä¸€ä½é€Ÿè®€åŠ©ç†ã€‚")
        if "âŒ" in note: return note
        combined_notes += f"\n\n--- Part {i+1} ---\n{note}"
        time.sleep(1)
        
    progress_bar.progress(0.9, text="æ­£åœ¨çµ±æ•´...")
    final_prompt = f"è«‹å°‡é€™äº›ç­†è¨˜æ•´åˆæˆå®Œæ•´çš„å­¸è¡“æ–‡ç»å›é¡§è¡¨(Markdown)ï¼š\n{combined_notes}"
    final_result = call_ai_api(final_prompt, sys_role="ä½ æ˜¯ä¸€ä½åšå­¸çš„æ•™æˆã€‚")
    progress_bar.progress(1.0, text="å®Œæˆï¼")
    return final_result

# --- æ ¸å¿ƒå‡½æ•¸ï¼šç”Ÿæˆ FCM åœ–è¡¨æ•¸æ“š ---
def generate_fcm_data():
    data = {
        'æ™‚é–“é€±æœŸ': ['t=0 (åˆå§‹)', 't=1 (æŠ•å…¥)', 't=2 (è½‰åŒ–)', 't=3 (ç”¢å‡º)', 't=4 (ç©©å®š)'],
        'C1 ç¶“è²»æŠ•å…¥': [0.20, 0.90, 0.90, 0.90, 0.90],
        'C7 å“¡å·¥ç”Ÿç”¢åŠ›': [0.50, 0.50, 0.60, 0.90, 1.00],
        'C9 é›¢è·ç‡': [0.70, 0.70, 0.55, 0.20, 0.05]
    }
    return pd.DataFrame(data).set_index('æ™‚é–“é€±æœŸ')

# --- åˆå§‹åŒ– ---
if 'step' not in st.session_state: st.session_state.step = 0
if 'final_title' not in st.session_state: st.session_state.final_title = ""
if 'refs' not in st.session_state: st.session_state.refs = ""
if 'parsed
