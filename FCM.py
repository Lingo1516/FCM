import streamlit as st
import pandas as pd
import requests
import json
import string
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="MCDM é›™éšæ®µç¯©é¸åˆ†æå™¨", layout="wide", page_icon="ğŸ§¬")

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ§¬ é›™è¡¨è¼¸å‡ºè¨­å®š")
    st.info("æ­¤ç‰ˆæœ¬å°‡åš´æ ¼å€åˆ†ç‚ºã€Œç¬¬ä¸€éšæ®µï¼šåŸå§‹åˆ—è¡¨ã€èˆ‡ã€Œç¬¬äºŒéšæ®µï¼šæ”¶æ–‚æ­¸ç´ã€ã€‚")
    
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    
    thesis_topic = st.text_input("è«–æ–‡é¡Œç›®ï¼š", value="é¤é£²æ¥­å°å…¥ AI æœå‹™ä¹‹è©•ä¼°æº–å‰‡")
    
    # è¨­å®šå…©éšæ®µæ•¸é‡
    c1, c2 = st.columns(2)
    with c1:
        pool_size = st.number_input("Step 1 åŸå§‹æ•¸é‡", value=50)
    with c2:
        target_size = st.number_input("Step 2 æ”¶æ–‚æ•¸é‡", value=15)

# --- 3. æ¨¡å‹é¸æ“‡ ---
def get_best_model(key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            for m in models: # å„ªå…ˆç”¨ Pro è™•ç†è¤‡é›œé‚è¼¯
                if 'gemini-1.5-pro' in m['name']: return m['name']
            for m in models:
                if 'gemini' in m['name']: return m['name']
        return "models/gemini-1.5-flash"
    except:
        return "models/gemini-1.5-flash"

# --- 4. æ ¸å¿ƒåˆ†æé‚è¼¯ (é›™è¡¨å°ˆç”¨ Prompt) ---
def run_two_stage_analysis(text, key, model_name, topic, pool_n, target_n):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ MCDM ç ”ç©¶å°ˆå®¶ã€‚ä½¿ç”¨è€…é¡Œç›®ï¼š{topic}ã€‚
    è«‹åŸ·è¡Œåš´æ ¼çš„ã€Œå…©éšæ®µæº–å‰‡ç¯©é¸ã€ï¼Œä¸¦å›å‚³ JSON è³‡æ–™ã€‚

    ã€ä»»å‹™ 1ï¼šå»ºç«‹æº–å‰‡æ±  (Pooling)ã€‘
    å¾æ–‡ç»ä¸­æ‰¾å‡ºç´„ {pool_n} å€‹ã€ŒåŸå§‹ç´°é …æº–å‰‡ (Raw Criteria)ã€ã€‚
    é€™äº›æ˜¯æœªç¶“ä¿®é£¾çš„ã€æ•£è½åœ¨å„æ–‡ç»ä¸­çš„å…·é«”æŒ‡æ¨™ã€‚

    ã€ä»»å‹™ 2ï¼šæº–å‰‡æ”¶æ–‚ (Convergence)ã€‘
    å°‡ä¸Šè¿°åŸå§‹æº–å‰‡é€²è¡Œé‚è¼¯åˆ†é¡èˆ‡åˆä½µï¼Œæ­¸ç´å‡º {target_n} å€‹ã€Œæœ€çµ‚æ§‹é¢/æº–å‰‡ (Final Criteria)ã€ã€‚
    å¿…é ˆæ¸…æ¥šèªªæ˜æ¯å€‹æœ€çµ‚æº–å‰‡åŒ…å«äº†å“ªäº›åŸå§‹æº–å‰‡ï¼Œä»¥åŠåˆä½µç†ç”±ã€‚

    ã€è¼¸å‡ºæ ¼å¼ (JSON)ã€‘ï¼š
    {{
      "step1_raw_pool": [
        {{ "id": 1, "name": "åŸå§‹æº–å‰‡A" }},
        {{ "id": 2, "name": "åŸå§‹æº–å‰‡B" }},
        ... (ç´„ {pool_n} å€‹)
      ],
      "step2_convergence": [
        {{
          "id": 1,
          "final_name": "æœ€çµ‚æº–å‰‡åç¨± (ä¾‹å¦‚ï¼šç‡Ÿé‹æˆæœ¬)",
          "source_raw_items": ["åŸå§‹æº–å‰‡A", "åŸå§‹æº–å‰‡B"],
          "reasoning": "Aèˆ‡Bçš†æ¶‰åŠè³‡é‡‘æ”¯å‡ºï¼Œæ•…åˆä½µç‚ºæˆæœ¬æ§‹é¢..."
        }},
        ... (ç´„ {target_n} å€‹)
      ]
    }}
    
    ã€åŸå§‹æ–‡ç»ã€‘ï¼š
    {text[:14000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            clean_json = res_text.replace("```json", "").replace("```", "").strip()
            return "OK", json.loads(clean_json)
        else:
            return "ERROR", f"éŒ¯èª¤ ({response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢ ---
st.title("ğŸ§¬ MCDM æº–å‰‡ï¼šé›™éšæ®µå ±å‘Šç”Ÿæˆ")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»æ‘˜è¦ï¼š", height=250)

if st.button("ğŸš€ åŸ·è¡Œé›™éšæ®µåˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹è¼¸å…¥ Key")
    elif not raw_text:
        st.warning("âš ï¸ è«‹è¼¸å…¥æ–‡ç»")
    else:
        with st.spinner(f"ğŸ” AI æ­£åœ¨é€²è¡Œå…©éšæ®µé‹ç®—ï¼šå…ˆåˆ—å‡º {pool_size} å€‹ï¼Œå†æ”¶æ–‚ç‚º {target_size} å€‹..."):
            valid_model = get_best_model(api_key)
            status, result = run_two_stage_analysis(raw_text, api_key, valid_model, thesis_topic, pool_size, target_size)
            
            if status == "OK":
                st.success("âœ… åˆ†æå®Œæˆï¼è«‹æŸ¥çœ‹ä¸‹æ–¹å…©å€‹åˆ†é ã€‚")
                
                # å»ºç«‹å…©å€‹åˆ†é 
                tab1, tab2 = st.tabs(["ğŸ“‘ è¡¨ä¸€ï¼šåŸå§‹æº–å‰‡æ±  (50é …)", "ğŸ¯ è¡¨äºŒï¼šæ”¶æ–‚æ­¸ç´è¡¨ (15é …)"])
                
                # --- Tab 1: åŸå§‹åˆ—è¡¨ ---
                with tab1:
                    raw_data = result.get("step1_raw_pool", [])
                    if raw_data:
                        df_raw = pd.DataFrame(raw_data)
                        df_raw.rename(columns={"id": "åºè™Ÿ", "name": "åŸå§‹ç´°é …æº–å‰‡åç¨±"}, inplace=True)
                        st.subheader(f"Step 1: åˆå§‹ç¯©é¸æº–å‰‡ (å…± {len(raw_data)} é …)")
                        st.dataframe(df_raw, hide_index=True, use_container_width=True)
                    else:
                        st.warning("AI æœªèƒ½ç”¢ç”ŸåŸå§‹åˆ—è¡¨")

                # --- Tab 2: æ”¶æ–‚çµæœ ---
                with tab2:
                    conv_data = result.get("step2_convergence", [])
                    if conv_data:
                        rows = []
                        for item in conv_data:
                            # æ•´ç†è³‡æ–™æ ¼å¼
                            row = {
                                "åºè™Ÿ": item.get("id"),
                                "æœ€çµ‚æº–å‰‡åç¨±": item.get("final_name"),
                                "æ¶µè“‹ä¹‹åŸå§‹ç´°é … (ä¾†è‡ªè¡¨ä¸€)": ", ".join(item.get("source_raw_items", [])),
                                "æ”¶æ–‚/åˆä½µç†ç”±èªªæ˜": item.get("reasoning") # é€™æ˜¯æœ€é‡è¦çš„æ¬„ä½
                            }
                            rows.append(row)
                        
                        df_conv = pd.DataFrame(rows)
                        st.subheader(f"Step 2: æœ€çµ‚æ”¶æ–‚æº–å‰‡ (å…± {len(conv_data)} é …)")
                        st.markdown("ğŸ‘‰ **æœ€å³å´æ¬„ä½** ç‚ºè©³ç´°çš„æ­¸ç´é‚è¼¯èªªæ˜")
                        st.dataframe(df_conv, hide_index=True, use_container_width=True)
                        
                        # --- ä¸‹è¼‰å€ ---
                        st.divider()
                        output = BytesIO()
                        try:
                            import xlsxwriter
                            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                if raw_data: df_raw.to_excel(writer, sheet_name='Step1_åŸå§‹æº–å‰‡(50)', index=False)
                                if conv_data: df_conv.to_excel(writer, sheet_name='Step2_æ”¶æ–‚æº–å‰‡(15)', index=False)
                            st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´é›™è¡¨ Excel", output.getvalue(), "mcdm_two_stage.xlsx", type="primary")
                        except:
                            st.error("Excel æ¨¡çµ„éŒ¯èª¤")

            else:
                st.error("åˆ†æå¤±æ•—")
                st.code(result)
