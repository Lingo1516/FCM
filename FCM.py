import streamlit as st
import pandas as pd
import google.generativeai as genai
import string
from io import BytesIO

# --- 1. è¨­å®šæ‚¨çš„ API Key (å·²å…§å»º) ---
# âš ï¸ å®‰å…¨è­¦å‘Šï¼šé€™æŠŠé‘°åŒ™æ˜¯æ‚¨çš„ç§å¯†è³‡è¨Šï¼Œè«‹å‹¿å°‡æ­¤ç¨‹å¼ç¢¼ç™¼å¸ƒåˆ°å…¬é–‹ç¶²è·¯ (GitHub/è«–å£‡)
USER_API_KEY = "AIzaSyBlj24gBVr3RJhkukS9p6yo5s2-WVBH2H0"

# è¨­å®š Google Gemini
genai.configure(api_key=USER_API_KEY)

# --- 2. é é¢è¨­å®š ---
st.set_page_config(page_title="AI æ–‡ç»åˆ†æå™¨ (è‡ªå‹•ç‰ˆ)", layout="wide", page_icon="ğŸ¤–")

st.title("ğŸ¤– AI æ™ºæ…§æ–‡ç»åˆ†æå™¨")
st.markdown("### å·²å…§å»ºé‡‘é‘°ï¼Œç›´æ¥è²¼ä¸Šæ–‡ç»å³å¯é–‹å§‹åˆ†æ")

# --- 3. è¼¸å…¥å€ ---
st.info("ğŸ‘‡ è«‹å°‡æ–‡ç»è³‡æ–™è²¼åœ¨ä¸‹æ–¹ (æ¯ä¸€ç¯‡è«‹è¨˜å¾— **æŒ‰ Enter æ›è¡Œ**)")
raw_text = st.text_area("æ–‡ç»è¼¸å…¥å€", height=300, placeholder="ç›´æ¥æŠŠäº‚äº‚çš„æ–‡å­—è²¼é€²ä¾†...\nè¨˜å¾—æ¯ä¸€ç¯‡è¦æ›è¡Œ...\nç¨‹å¼æœƒè‡ªå‹•å¹«ä½ æŠ“é‡é»...")

# --- 4. æ ¸å¿ƒé‚è¼¯ï¼šå‘¼å« Google AI ---
def get_ai_analysis(text):
    # ä½¿ç”¨å…è²»å¿«é€Ÿçš„ Flash æ¨¡å‹
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½å­¸è¡“ç ”ç©¶å°ˆå®¶ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç»å…§å®¹ï¼Œå¹«æˆ‘æ­¸ç´å‡º 10 åˆ° 15 å€‹æœ€é‡è¦çš„ã€Œç ”ç©¶æ§‹é¢ã€æˆ–ã€Œè©•ä¼°æº–å‰‡ã€ã€‚
    
    ã€åš´æ ¼è¦å‰‡ã€‘ï¼š
    1. æ’é™¤æ‰€æœ‰ç„¡é—œè©å½™ï¼ˆå¦‚ï¼šæ—¥æœŸã€ä¸‹åˆã€å ±å‘Šã€ä½œè€…åã€ç ”ç©¶æ–¹æ³•ï¼‰ã€‚
    2. åªä¿ç•™å…·å‚™å­¸è¡“åƒ¹å€¼çš„åè©ï¼ˆä¾‹å¦‚ï¼šç¸¾æ•ˆç®¡ç†ã€æ•¸ä½è½‰å‹ã€ä¾›æ‡‰éˆéŸŒæ€§ã€ESGã€ç²åˆ©èƒ½åŠ›ï¼‰ã€‚
    3. ç›´æ¥è¼¸å‡ºåè©ï¼Œç”¨ã€Œã€ã€é “è™Ÿéš”é–‹ã€‚ä¸è¦æœ‰ä»»ä½•é–‹å ´ç™½æˆ–çµå°¾ã€‚
    
    ã€æ–‡ç»å…§å®¹ã€‘ï¼š
    {text[:10000]} 
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# --- 5. è¼”åŠ©é‚è¼¯ï¼šåˆ‡å‰²æ–‡ç» ---
def parse_text(text):
    lines = text.strip().split('\n')
    literature_list = []
    
    for line in lines:
        line = line.strip()
        if len(line) < 5: continue
        
        # è‡ªå‹•å–å‰ 15 å­—ç•¶æ¨™é¡Œ
        title = line[:15] + "..." if len(line) > 15 else line
        literature_list.append({"title": title, "content": line})
        
    return literature_list

# --- 6. åŸ·è¡ŒæŒ‰éˆ• ---
if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè²¼ä¸Šè³‡æ–™ï¼")
    else:
        with st.spinner("ğŸ¤– AI æ­£åœ¨é–±è®€æ‚¨çš„æ–‡ç»ä¸¦æ­¸ç´é‡é»..."):
            # A. åˆ‡å‰²è³‡æ–™
            lit_data = parse_text(raw_text)
            
            if not lit_data:
                st.error("ç„¡æ³•åˆ‡å‰²è³‡æ–™ï¼Œè«‹ç¢ºèªæ¯ç¯‡æ–‡ç»æœ‰æ›è¡Œã€‚")
            else:
                # B. å‘¼å« AI
                ai_result = get_ai_analysis(raw_text)
                
                if "Error" in ai_result:
                    st.error(f"é€£ç·šéŒ¯èª¤ï¼š{ai_result} (å¯èƒ½æ˜¯é¡åº¦å·²æ»¿æˆ– Key è¢«åœç”¨)")
                else:
                    st.success("âœ… AI åˆ†æå®Œæˆï¼")
                    
                    # C. æ•´ç†é—œéµå­—
                    keywords = [k.strip() for k in ai_result.replace("\n", "ã€").split("ã€") if k.strip()]
                    # å»é™¤é‡è¤‡
                    keywords = list(dict.fromkeys(keywords))
                    
                    # D. è®“ä½¿ç”¨è€…ç¯©é¸
                    st.subheader("1ï¸âƒ£ AI å»ºè­°çš„æº–å‰‡ (å¯åˆªæ¸›)")
                    final_keywords = st.multiselect(
                        "è«‹å‹¾é¸è¦ä¿ç•™çš„æº–å‰‡ï¼š",
                        options=keywords,
                        default=keywords
                    )
                    
                    # æ‰‹å‹•è£œå……
                    manual_add = st.text_input("æ‰‹å‹•è£œå……æº–å‰‡ (ç”¨ç©ºç™½éš”é–‹)ï¼š", placeholder="ä¾‹å¦‚ï¼šå‰µæ–°èƒ½åŠ› çµ„ç¹”æ–‡åŒ–")
                    if manual_add:
                        final_keywords = manual_add.split() + final_keywords

                    if final_keywords:
                        # E. å»ºç«‹çŸ©é™£
                        matrix = {}
                        labels = []
                        titles = []
                        
                        def get_label(idx):
                            if idx < 26: return string.ascii_uppercase[idx]
                            else: return f"{string.ascii_uppercase[idx // 26 - 1]}{string.ascii_uppercase[idx % 26]}"

                        for i, item in enumerate(lit_data):
                            label = get_label(i)
                            labels.append(label)
                            titles.append(item['title'])
                            
                            col_res = []
                            for kw in final_keywords:
                                if kw in item['content']:
                                    col_res.append("â—‹")
                                else:
                                    col_res.append("")
                            matrix[label] = col_res
                        
                        # F. é¡¯ç¤ºçµæœ
                        df_matrix = pd.DataFrame(matrix, index=final_keywords)
                        df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "å°æ‡‰æ–‡ç»": titles})
                        
                        st.divider()
                        c1, c2 = st.columns([2, 1])
                        with c1:
                            st.subheader("ğŸ“Š åˆ†æçŸ©é™£")
                            st.dataframe(df_matrix, use_container_width=True)
                        with c2:
                            st.subheader("ğŸ“ å°ç…§è¡¨")
                            st.dataframe(df_legend, hide_index=True, use_container_width=True)
                        
                        # G. ä¸‹è¼‰
                        output = BytesIO()
                        try:
                            import xlsxwriter
                            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                df_matrix.to_excel(writer, sheet_name='çŸ©é™£')
                                df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                            file_name = "ai_analysis.xlsx"
                            mime = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        except ImportError:
                            df_matrix.to_csv(output, encoding='utf-8-sig')
                            file_name = "ai_analysis.csv"
                            mime = "text/csv"
                            
                        st.download_button(f"ğŸ“¥ ä¸‹è¼‰å ±è¡¨ ({file_name})", output.getvalue(), file_name, mime, type="primary")
