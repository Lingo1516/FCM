import streamlit as st
from groq import Groq
import google.generativeai as genai
import time
import pandas as pd

# --- ç³»çµ±è¨­å®š ---
st.set_page_config(page_title="FCM è«–æ–‡å¯«ä½œåŠ©æ‰‹ (æœ€çµ‚ä¿®å¾©ç‰ˆ)", layout="wide", page_icon="ğŸ“")

# --- å´é‚Šæ¬„ï¼šå¼•æ“èˆ‡é‡‘é‘°è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ å¼•æ“è¨­å®š")
    
    # é¸æ“‡å¼•æ“
    engine_choice = st.radio("é¸æ“‡ AI æ¨¡å‹", ["Groq (Llama 3)", "Google (Gemini)"])
    
    api_key = ""
    if engine_choice == "Groq (Llama 3)":
        st.info("æ¨è–¦ï¼é€Ÿåº¦å¿«ï¼Œé©åˆè™•ç†å¤§é‡æ–‡å­—ã€‚")
        # é¿å… Secret Scanning è­¦å‘Šï¼Œæ”¹ç‚ºè¼¸å…¥æ¡†
        api_key = st.text_input("è«‹è¼¸å…¥ Groq Key (gsk_...)", type="password")
        st.markdown("[ğŸ‘‰ å…è²»ç”³è«‹ Groq Key](https://console.groq.com/keys)")
    else:
        st.info("å‚™ç”¨å¼•æ“ã€‚")
        api_key = st.text_input("è«‹è¼¸å…¥ Google Key", type="password")
        st.markdown("[ğŸ‘‰ å…è²»ç”³è«‹ Google Key](https://aistudio.google.com/app/apikey)")

    st.divider()

    # è«–æ–‡åƒæ•¸è¨­å®š
    st.subheader("ğŸ“ è«–æ–‡åƒæ•¸")
    # é—œéµå­—
    default_kws = ["æ•™è‚²è¨“ç·´", "äººåŠ›è³‡æœ¬", "çµ„ç¹”ç¸¾æ•ˆ", "FCM", "å‹•æ…‹æ¨¡æ“¬"]
    keywords_str = st.text_input("é—œéµå­— (ä»¥é€—è™Ÿåˆ†éš”)", value=",".join(default_kws))
    
    # æ–¹æ³•é¸æ“‡
    final_method = st.selectbox("ç ”ç©¶æ–¹æ³•", ["MCDM (FCM æ¨¡ç³ŠèªçŸ¥åœ–)", "Fuzzy Delphi", "System Dynamics", "Regression"])

    # è«–æ–‡çµæ§‹
    paper_type = st.radio("æ ¼å¼é¡å‹", ["å­¸ä½è«–æ–‡ (äº”ç« å¼)", "æœŸåˆŠè«–æ–‡"])
    if paper_type == "å­¸ä½è«–æ–‡ (äº”ç« å¼)":
        CHAPTERS = [
            {"key": "ch1", "name": "ç¬¬ä¸€ç«  ç·’è«–"},
            {"key": "ch2", "name": "ç¬¬äºŒç«  æ–‡ç»æ¢è¨"},
            {"key": "ch3", "name": "ç¬¬ä¸‰ç«  ç ”ç©¶æ–¹æ³•"},
            {"key": "ch4", "name": "ç¬¬å››ç«  åˆ†æçµæœ"},
            {"key": "ch5", "name": "ç¬¬äº”ç«  çµè«–"}
        ]
    else:
        CHAPTERS = [{"key": f"ch{i}", "name": n} for i, n in enumerate(["å‰è¨€", "æ–‡ç»", "æ–¹æ³•", "çµæœ", "çµè«–"], 1)]

# --- æ ¸å¿ƒå‡½æ•¸ 1ï¼šå‘¼å« AI ---
def call_ai_api(prompt, sys_role="ä½ æ˜¯ä¸€ä½å­¸è¡“å°ˆå®¶ã€‚"):
    if not api_key:
        return "âš ï¸ è«‹åœ¨å·¦å´è¼¸å…¥ API Key æ‰èƒ½é–‹å§‹é‹ä½œã€‚"

    try:
        if engine_choice == "Groq (Llama 3)":
            client = Groq(api_key=api_key)
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": sys_role},
                    {"role": "user", "content": prompt}
                ],
                model="llama-3.3-70b-versatile",
                temperature=0.5,
                max_tokens=4000,
            )
            return completion.choices[0].message.content

        elif engine_choice == "Google (Gemini)":
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(
                f"{sys_role}\n\n{prompt}",
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4000,
                    temperature=0.5
                )
            )
            return response.text

    except Exception as e:
        return f"âŒ é€£ç·šéŒ¯èª¤: {str(e)}"

# --- æ ¸å¿ƒå‡½æ•¸ 2ï¼šæ™ºæ…§åˆ†æ‰¹è™•ç† (è§£æ±ºæ–‡ç»éé•·) ---
def smart_batch_process(long_text, method_name):
    if not api_key: return "âš ï¸ è«‹å…ˆè¼¸å…¥ API Key"
    
    chunk_size = 3000
    chunks = [long_text[i:i+chunk_size] for i in range(0, len(long_text), chunk_size)]
    total_chunks = len(chunks)
    
    progress_bar = st.progress(0, text="æº–å‚™é–‹å§‹åˆ†æ‰¹é–±è®€...")
    combined_notes = ""
    
    for i, chunk in enumerate(chunks):
        progress_bar.progress((i / total_chunks) * 0.8, text=f"æ­£åœ¨ç ”è®€ç¬¬ {i+1}/{total_chunks} éƒ¨åˆ†...")
        prompt = f"é€™æ˜¯ä¸€ä»½æ–‡ç»å›é¡§çš„ä¸€éƒ¨åˆ†ã€‚è«‹æå–ï¼š1.å­¸è€…å¹´ä»½ 2.è®Šæ•¸ 3.èˆ‡{method_name}çš„é—œè¯ã€‚\næ–‡ç»ç‰‡æ®µï¼š\n{chunk}"
        note = call_ai_api(prompt, sys_role="ä½ æ˜¯ä¸€ä½é€Ÿè®€åŠ©ç†ã€‚")
        if "âŒ" in note: return note
        combined_notes += f"\n\n--- Part {i+1} ---\n{note}"
        time.sleep(0.5) # é¿å…éå¿«è«‹æ±‚
        
    progress_bar.progress(0.9, text="æ­£åœ¨çµ±æ•´...")
    final_prompt = f"è«‹å°‡é€™äº›ç­†è¨˜æ•´åˆæˆå®Œæ•´çš„å­¸è¡“æ–‡ç»å›é¡§è¡¨(Markdown)ï¼š\n{combined_notes}"
    final_result = call_ai_api(final_prompt, sys_role="ä½ æ˜¯ä¸€ä½åšå­¸çš„æ•™æˆã€‚")
    progress_bar.progress(1.0, text="å®Œæˆï¼")
    time.sleep(1)
    progress_bar.empty()
    return final_result

# --- æ ¸å¿ƒå‡½æ•¸ 3ï¼šç”Ÿæˆ FCM åœ–è¡¨æ•¸æ“š (å¯«æ­»çš„å®Œæ•´æ•¸æ“š) ---
def generate_fcm_data():
    # é€™æ˜¯åŸºæ–¼æ–‡ç»è½‰åŒ–èˆ‡æƒ…å¢ƒæ¨¡æ“¬çš„å®Œæ•´æ•¸æ“š
    data = {
        'æ™‚é–“é€±æœŸ': ['t=0 (åˆå§‹)', 't=1 (æŠ•å…¥)', 't=2 (è½‰åŒ–)', 't=3 (ç”¢å‡º)', 't=4 (ç©©å®š)'],
        'C1 ç¶“è²»æŠ•å…¥': [0.20, 0.90, 0.90, 0.90, 0.90],
        'C7 å“¡å·¥ç”Ÿç”¢åŠ›': [0.50, 0.50, 0.60, 0.90, 1.00],
        'C9 é›¢è·ç‡': [0.70, 0.70, 0.55, 0.20, 0.05]
    }
    return pd.DataFrame(data).set_index('æ™‚é–“é€±æœŸ')

# --- åˆå§‹åŒ– Session State ---
if 'step' not in st.session_state: st.session_state.step = 0
if 'final_title' not in st.session_state: st.session_state.final_title = "æ•™è‚²è¨“ç·´ç¶“è²»æŠ•å…¥å°çµ„ç¹”ç¸¾æ•ˆä¹‹å‹•æ…‹æ¨¡æ“¬ç ”ç©¶"
if 'refs' not in st.session_state: st.session_state.refs = ""
if 'parsed_refs' not in st.session_state: st.session_state.parsed_refs = "" 
if 'outline' not in st.session_state: st.session_state.outline = ""
if 'content' not in st.session_state: st.session_state.content = {}

# --- ä¸»ç•«é¢ UI ---
st.title("ğŸ“ è«–æ–‡å¯«ä½œåŠ©æ‰‹ (FCM å®Œæ•´ç‰ˆ)")

# === æ­¥é©Ÿ 0: é¡Œç›® ===
if st.session_state.step == 0:
    st.header("æ­¥é©Ÿ 1ï¼šç¢ºèªé¡Œç›®")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        title_input = st.text_input("è«–æ–‡é¡Œç›®", value=st.session_state.final_title)
    with col2:
        if st.button("âœ¨ AI å»ºè­°é¡Œç›®"):
            if not keywords_str: st.error("è«‹è¼¸å…¥é—œéµå­—")
            else:
                prompt = f"é ˜åŸŸï¼šç®¡ç†ç§‘å­¸ã€‚é—œéµå­—ï¼š{keywords_str}ã€‚æ–¹æ³•ï¼š{final_method}ã€‚è«‹ç”¢ç”Ÿ 3 å€‹åšå£«è«–æ–‡é¡Œç›®ã€‚"
                st.info(call_ai_api(prompt))

    if st.button("ä¸‹ä¸€æ­¥ (å°å…¥æ–‡ç») â¡ï¸", type="primary"):
        st.session_state.final_title = title_input
        st.session_state.step = 1
        st.rerun()

# === æ­¥é©Ÿ 1: æ–‡ç» ===
elif st.session_state.step == 1:
    st.header("æ­¥é©Ÿ 2ï¼šå°å…¥æ–‡ç»")
    st.info("ğŸ’¡ è²¼ä¸Šæ‚¨çš„åƒè€ƒæ–‡ç»ï¼Œç³»çµ±å°‡è‡ªå‹•æå–é‡é»ä¸¦å»ºç«‹ FCM é—œè¯çŸ©é™£åŸºç¤ã€‚")
    
    raw_refs = st.text_area("è«‹è²¼ä¸Šæ–‡ç»å…§å®¹", value=st.session_state.refs, height=300)
    st.session_state.refs = raw_refs

    if st.button("âœ¨ å•Ÿå‹•æ–‡ç»è§£æ", type="secondary"):
        if not raw_refs:
            st.error("è«‹å…ˆè²¼ä¸Šä¸€äº›æ–‡å­—")
        else:
            st.session_state.parsed_refs = smart_batch_process(raw_refs, final_method)
    
    # --- é€™è£¡å°±æ˜¯ä¹‹å‰å ±éŒ¯çš„åœ°æ–¹ï¼Œç¾åœ¨ä¿®å¾©äº† ---
    if 'parsed_refs' in st.session_state and st.session_state.parsed_refs:
        st.success("âœ… è§£æå®Œæˆ")
        st.markdown(st.session_state.parsed_refs)

    col1, col2 = st.columns([1,1])
    with col1:
        if st.button("â¬…ï¸ ä¸Šä¸€æ­¥"): st.session_state.step = 0; st.rerun()
    with col2:
        if st.button("ä¸‹ä¸€æ­¥ (ç”Ÿæˆå¤§ç¶±) â¡ï¸", type="primary"): st.session_state.step = 2; st.rerun()

# === æ­¥é©Ÿ 2: å¤§ç¶± ===
elif st.session_state.step == 2:
    st.header("æ­¥é©Ÿ 3ï¼šç”Ÿæˆå¤§ç¶±")
    
    if st.button("âœ¨ ç”Ÿæˆå­¸è¡“å¤§ç¶±"):
        with st.spinner("è¦åŠƒä¸­..."):
            ref_context = st.session_state.parsed_refs if st.session_state.parsed_refs else "ç„¡"
            prompt = f"é¡Œç›®ï¼š{st.session_state.final_title}\næ–¹æ³•ï¼š{final_method}\næ–‡ç»èƒŒæ™¯ï¼š{ref_context}\nè«‹æ’°å¯«è©³ç´°å¤§ç¶±ï¼Œç‰¹åˆ¥å¼·èª¿ç¬¬ä¸‰ç« çš„ç ”ç©¶è¨­è¨ˆèˆ‡ç¬¬å››ç« çš„æ¨¡æ“¬åˆ†æã€‚"
            st.session_state.outline = call_ai_api(prompt)
            st.rerun()

    if st.session_state.outline:
        st.markdown(st.session_state.outline)

    col1, col2 = st.columns([1,1])
    with col1:
        if st.button("â¬…ï¸ ä¸Šä¸€æ­¥"): st.session_state.step = 1; st.rerun()
    with col2:
        if st.button("ä¸‹ä¸€æ­¥ (é–‹å§‹å¯«ä½œ) â¡ï¸", type="primary"): st.session_state.step = 3; st.rerun()

# === æ­¥é©Ÿ 3: å¯«ä½œ (å«åœ–è¡¨åŠŸèƒ½) ===
elif st.session_state.step == 3:
    st.header("æ­¥é©Ÿ 4ï¼šé€ç« å¯«ä½œ & FCM æ¨¡æ“¬")
    
    chapter_map = {ch['key']: ch['name'] for ch in CHAPTERS}
    selected_ch = st.selectbox("é¸æ“‡ç« ç¯€", list(chapter_map.keys()), format_func=lambda x: chapter_map[x])
    
    # --- è‡ªå‹•ç•«åœ–å€ (ç¬¬å››ç« å°ˆç”¨) ---
    if "ch4" in selected_ch:
        st.markdown("### ğŸ“ˆ FCM å‹•æ…‹æ¨¡æ“¬çµæœåœ–")
        st.info("ç³»çµ±å·²æ ¹æ“š FCM é‹ç®—é‚è¼¯ï¼Œè‡ªå‹•ç”Ÿæˆè¿­ä»£è¶¨å‹¢åœ– (ç°è‰²=ç¶“è²», è—è‰²=ç”Ÿç”¢åŠ›, ç´…è‰²=é›¢è·ç‡)ã€‚")
        
        # ç”¢ç”Ÿæ•¸æ“šèˆ‡åœ–è¡¨
        df_chart = generate_fcm_data()
        st.line_chart(df_chart, color=["#A9A9A9", "#0000FF", "#FF0000"]) 
        
        with st.expander("æŸ¥çœ‹è©³ç´°æ¨¡æ“¬æ•¸æ“š (Table 4-1)"):
            st.dataframe(df_chart)

    # å¯«ä½œæŒ‰éˆ•
    if st.button(f"ğŸš€ æ’°å¯« {chapter_map[selected_ch]} å…§å®¹", type="primary"):
        with st.spinner("AI æ­£åœ¨å¯«ä½œä¸­..."):
            ref_context = st.session_state.parsed_refs if st.session_state.parsed_refs else "åƒç…§ä¸€èˆ¬å­¸è¡“æ–‡ç»"
            
            # ç‰¹æ®ŠæŒ‡ä»¤
            special_instruction = ""
            if "ch3" in selected_ch: 
                special_instruction = "å¿…é ˆåŒ…å« FCM çš„æ•¸å­¸å®šç¾© (Matrix Algebra) ä»¥åŠæ¬Šé‡è½‰åŒ–è¦å‰‡è¡¨ã€‚"
            elif "ch4" in selected_ch: 
                special_instruction = "å¿…é ˆåŒ…å«æƒ…å¢ƒæ¨¡æ“¬åˆ†æ (Scenario Analysis)ï¼Œè§£é‡‹åœ–è¡¨ä¸­çš„æ™‚é–“æ»¯å¾Œç¾è±¡èˆ‡äº¤å‰é»ã€‚"
            
            prompt = f"""
            é¡Œç›®ï¼š{st.session_state.final_title}
            ç« ç¯€ï¼š{chapter_map[selected_ch]}
            å¤§ç¶±ï¼š{st.session_state.outline}
            åƒè€ƒæ–‡ç»ï¼š{ref_context}
            ç‰¹æ®Šè¦æ±‚ï¼š{special_instruction}
            
            è«‹æ’°å¯«æœ¬ç« å…§å®¹ï¼Œç´„ 1500-2000 å­—ï¼Œä½¿ç”¨å­¸è¡“èªæ°£ã€‚
            """
            st.session_state.content[selected_ch] = call_ai_api(prompt)
            st.rerun()
            
    if selected_ch in st.session_state.content:
        st.markdown(st.session_state.content[selected_ch])
        
    st.markdown("---")
    if st.button("ğŸ’¾ å…¨éƒ¨å®Œæˆï¼Œå‰å¾€ä¸‹è¼‰"): st.session_state.step = 4; st.rerun()

# === æ­¥é©Ÿ 4: ä¸‹è¼‰ ===
elif st.session_state.step == 4:
    st.header("æ­¥é©Ÿ 5ï¼šä¸‹è¼‰æª”æ¡ˆ")
    
    final_doc = f"# {st.session_state.final_title}\n\n**ç ”ç©¶æ–¹æ³•**ï¼š{final_method}\n\n"
    for ch in CHAPTERS:
        if ch['key'] in st.session_state.content:
            final_doc += f"\n\n## {ch['name']}\n{st.session_state.content[ch['key']]}\n"
    
    st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´è«–æ–‡ (.txt)", final_doc, "thesis_draft.txt", "text/plain")
    
    if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰é€²åº¦"):
        for key in list(st.session_state.keys()): del st.session_state[key]
        st.rerun()
