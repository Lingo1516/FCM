import streamlit as st
import pandas as pd
import requests
import json
import string
import re
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="MCDM é›™éšæ®µç¯©é¸åˆ†æå™¨ (å¼·æ•ˆç‰ˆ)", layout="wide", page_icon="ğŸ§¬")

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ§¬ é›™è¡¨è¼¸å‡ºè¨­å®š")
    st.info("æ­¤ç‰ˆæœ¬å¢åŠ äº† JSON å¼·åŠ›æ¸…æ´—åŠŸèƒ½ï¼Œèƒ½é˜²æ­¢æ ¼å¼éŒ¯èª¤ã€‚")
    
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    
    thesis_topic = st.text_input("è«–æ–‡é¡Œç›®ï¼š", value="é¤é£²æ¥­å°å…¥ AI æœå‹™ä¹‹è©•ä¼°æº–å‰‡")
    
    # è¨­å®šå…©éšæ®µæ•¸é‡
    c1, c2 = st.columns(2)
    with c1:
        pool_size = st.number_input("Step 1 åŸå§‹æ•¸é‡", value=50)
    with c2:
        target_size = st.number_input("Step 2 æ”¶æ–‚æ•¸é‡", value=15)

# --- 3. æ¨¡å‹é¸æ“‡ ---
def get_best_model(key):
    # å„ªå…ˆå˜—è©¦ Proï¼Œè‹¥å¤±æ•—å‰‡é€€å› Flash
    return "models/gemini-1.5-pro"

# --- 4. æ ¸å¿ƒåˆ†æé‚è¼¯ (å¢åŠ  Regex æ¸…æ´—) ---
def run_two_stage_analysis(text, key, model_name, topic, pool_n, target_n):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ MCDM ç ”ç©¶å°ˆå®¶ã€‚ä½¿ç”¨è€…é¡Œç›®ï¼š{topic}ã€‚
    è«‹åŸ·è¡Œåš´æ ¼çš„ã€Œå…©éšæ®µæº–å‰‡ç¯©é¸ã€ï¼Œä¸¦å›å‚³ JSON è³‡æ–™ã€‚

    ã€ä»»å‹™ 1ï¼šå»ºç«‹æº–å‰‡æ±  (Pooling)ã€‘
    å¾æ–‡ç»ä¸­æ‰¾å‡ºç´„ {pool_n} å€‹ã€ŒåŸå§‹ç´°é …æº–å‰‡ (Raw Criteria)ã€ã€‚

    ã€ä»»å‹™ 2ï¼šæº–å‰‡æ”¶æ–‚ (Convergence)ã€‘
    å°‡ä¸Šè¿°åŸå§‹æº–å‰‡é€²è¡Œé‚è¼¯åˆ†é¡èˆ‡åˆä½µï¼Œæ­¸ç´å‡º {target_n} å€‹ã€Œæœ€çµ‚æ§‹é¢/æº–å‰‡ (Final Criteria)ã€ã€‚

    ã€è¼¸å‡ºæ ¼å¼ (JSON Only)ã€‘ï¼š
    è«‹å‹™å¿…åªå›å‚³ JSONï¼Œä¸è¦æœ‰ markdown code blockï¼Œä¸è¦æœ‰è§£é‡‹æ–‡å­—ã€‚
    {{
      "step1_raw_pool": [
        {{ "id": 1, "name": "åŸå§‹æº–å‰‡A" }},
        ... (ç´„ {pool_n} å€‹)
      ],
      "step2_convergence": [
        {{
          "id": 1,
          "final_name": "æœ€çµ‚æº–å‰‡åç¨±",
          "source_raw_items": ["åŸå§‹æº–å‰‡A", "åŸå§‹æº–å‰‡B"],
          "reasoning": "åˆä½µç†ç”±..."
        }},
        ... (ç´„ {target_n} å€‹)
      ]
    }}
    
    æ–‡ç»ï¼š
    {text[:12000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            try:
                res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            except:
                return "ERROR", "AI å›å‚³çµæ§‹ç•°å¸¸ï¼Œå¯èƒ½è¢«å®‰å…¨é˜»æ“‹ã€‚"

            # --- å¼·åŠ›æ¸…æ´—ï¼šåªæŠ“å–ç¬¬ä¸€å€‹ { åˆ°æœ€å¾Œä¸€å€‹ } ä¹‹é–“çš„å…§å®¹ ---
            match = re.search(r'\{.*\}', res_text, re.DOTALL)
            if match:
                clean_json_str = match.group(0)
                try:
                    return "OK", json.loads(clean_json_str)
                except json.JSONDecodeError as e:
                    return "ERROR", f"JSON è§£æå¤±æ•—: {e}\n\nAI å›å‚³åŸå§‹å…§å®¹:\n{clean_json_str}"
            else:
                return "ERROR", f"æ‰¾ä¸åˆ° JSON çµæ§‹ã€‚\nAI å›å‚³å…§å®¹:\n{res_text}"
        else:
            return "ERROR", f"API é€£ç·šéŒ¯èª¤ ({response.status_code}): {response.text}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢ ---
st.title("ğŸ§¬ MCDM æº–å‰‡ï¼šé›™éšæ®µå ±å‘Šç”Ÿæˆ")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»æ‘˜è¦ï¼š", height=250)

if st.button("ğŸš€ åŸ·è¡Œé›™éšæ®µåˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹è¼¸å…¥ Key")
    elif not raw_text:
        st.warning("âš ï¸ è«‹è¼¸å…¥æ–‡ç»")
    else:
        with st.spinner(f"ğŸ” AI æ­£åœ¨é€²è¡Œé‹ç®— (é€™å¯èƒ½éœ€è¦ 30 ç§’)..."):
            # é€™è£¡æˆ‘å€‘ç”¨ try-except åŒ…èµ·ä¾†ï¼Œå¦‚æœ Pro å¤±æ•—è‡ªå‹•åˆ‡æ› Flash
            try:
                valid_model = "models/gemini-1.5-pro"
                status, result = run_two_stage_analysis(raw_text, api_key, valid_model, thesis_topic, pool_size, target_size)
            except:
                st.warning("Pro æ¨¡å‹å¤±æ•—ï¼Œåˆ‡æ›è‡³ Flash æ¨¡å‹é‡è©¦...")
                valid_model = "models/gemini-1.5-flash"
                status, result = run_two_stage_analysis(raw_text, api_key, valid_model, thesis_topic, pool_size, target_size)
            
            if status == "OK":
                st.success("âœ… åˆ†æå®Œæˆï¼")
                
                # å»ºç«‹å…©å€‹åˆ†é 
                tab1, tab2 = st.tabs(["ğŸ“‘ è¡¨ä¸€ï¼šåŸå§‹æº–å‰‡æ±  (50é …)", "ğŸ¯ è¡¨äºŒï¼šæ”¶æ–‚æ­¸ç´è¡¨ (15é …)"])
                
                # --- Tab 1 ---
                with tab1:
                    raw_data = result.get("step1_raw_pool", [])
                    if raw_data:
                        df_raw = pd.DataFrame(raw_data)
                        if "id" in df_raw.columns:
                            df_raw.rename(columns={"id": "åºè™Ÿ", "name": "åŸå§‹ç´°é …æº–å‰‡åç¨±"}, inplace=True)
                        st.dataframe(df_raw, hide_index=True, use_container_width=True)

                # --- Tab 2 ---
                with tab2:
                    conv_data = result.get("step2_convergence", [])
                    if conv_data:
                        rows = []
                        for item in conv_data:
                            row = {
                                "åºè™Ÿ": item.get("id"),
                                "æœ€çµ‚æº–å‰‡åç¨±": item.get("final_name"),
                                "æ¶µè“‹ä¹‹åŸå§‹ç´°é …": ", ".join(item.get("source_raw_items", [])),
                                "æ”¶æ–‚/åˆä½µç†ç”±èªªæ˜": item.get("reasoning")
                            }
                            rows.append(row)
                        
                        df_conv = pd.DataFrame(rows)
                        st.markdown("ğŸ‘‰ **å‘å³æ»‘å‹•æŸ¥çœ‹è©³ç´°æ­¸ç´é‚è¼¯**")
                        st.dataframe(df_conv, hide_index=True, use_container_width=True)
                        
                        # ä¸‹è¼‰
                        output = BytesIO()
                        try:
                            import xlsxwriter
                            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                if raw_data: df_raw.to_excel(writer, sheet_name='Step1_åŸå§‹æº–å‰‡', index=False)
                                if conv_data: df_conv.to_excel(writer, sheet_name='Step2_æ”¶æ–‚æº–å‰‡', index=False)
                            st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´é›™è¡¨ Excel", output.getvalue(), "mcdm_two_stage.xlsx", type="primary")
                        except:
                            st.error("Excel æ¨¡çµ„éŒ¯èª¤")
            else:
                st.error("åˆ†æå¤±æ•—ï¼Œè«‹æŸ¥çœ‹ä¸‹æ–¹éŒ¯èª¤è¨Šæ¯ï¼š")
                st.code(result) # æŠŠéŒ¯èª¤è¨Šæ¯ç›´æ¥å°å‡ºä¾†
