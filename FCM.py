import streamlit as st
import pandas as pd
import requests
import json
import string
import re
from io import BytesIO

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="MCDM å…¨åŠŸèƒ½å±¤ç´šåˆ†æç³»çµ±", layout="wide", page_icon="ğŸ’")

# --- 2. å´é‚Šæ¬„ (å®‰å…¨æ€§ + åƒæ•¸è¨­å®š) ---
with st.sidebar:
    st.header("ğŸ’ ç³»çµ±è¨­å®š")
    
    # === å®‰å…¨æ€§æª¢æŸ¥ï¼šå„ªå…ˆè®€å– Secrets ===
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… å·²è¼‰å…¥é›²ç«¯é‡‘é‘° (å®‰å…¨æ¨¡å¼)")
    else:
        st.warning("âš ï¸ æœªåµæ¸¬åˆ°é›²ç«¯é‡‘é‘°")
        api_key = st.text_input("è«‹æ‰‹å‹•è¼¸å…¥ API Key", type="password")
    # ===================================

    st.divider()
    thesis_topic = st.text_input("è«–æ–‡é¡Œç›®ï¼š", value="é¤é£²æ¥­å°å…¥ AI æœå‹™ä¹‹è©•ä¼°æº–å‰‡")
    
    st.subheader("ğŸ“Š ç ”ç©¶åƒæ•¸è¨­å®š")
    st.caption("è«‹è¨­å®šæ‚¨å¸Œæœ› AI æ­¸ç´çš„æ•¸é‡ç´šè·ï¼š")
    c1, c2, c3 = st.columns(3)
    with c1:
        pool_size = st.number_input("1.åŸå§‹æ± ", value=50, help="Step 1: é è¨ˆå¾æ–‡ç»æ‰¾å‡ºå¤šå°‘å€‹ç´°é …")
    with c2:
        criteria_size = st.number_input("2.æº–å‰‡æ•¸", value=15, help="Step 2: æ”¶æ–‚å¾Œå¸Œæœ›å‰©ä¸‹å¤šå°‘å€‹æº–å‰‡")
    with c3:
        dim_size = st.number_input("3.æ§‹é¢æ•¸", value=4, help="Step 3: å°‡æº–å‰‡æ­¸ç´ç‚ºå¹¾å€‹æ§‹é¢")

# --- 3. æ¨¡å‹è‡ªå‹•é©é… (é˜²å‘†æ©Ÿåˆ¶) ---
def get_best_model(key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            # å„ªå…ˆé †åº: Pro (è°æ˜) -> Flash (å¿«) -> å…¶ä»–
            for m in models:
                if 'gemini-1.5-pro' in m['name']: return m['name']
            for m in models:
                if 'gemini-1.5-flash' in m['name']: return m['name']
            for m in models:
                if 'gemini' in m['name'] and 'generateContent' in m.get('supportedGenerationMethods', []):
                    return m['name']
            return None
        return None
    except:
        return None

# --- 4. æ ¸å¿ƒåˆ†æé‚è¼¯ (åŒ…å«æ‰€æœ‰å±¤ç´šèˆ‡çŸ©é™£è³‡è¨Š) ---
def run_full_analysis(text, key, model_name, topic, pool_n, crit_n, dim_n):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ MCDM ç ”ç©¶å°ˆå®¶ã€‚é¡Œç›®ï¼š{topic}ã€‚
    è«‹åŸ·è¡Œå®Œæ•´çš„ã€Œæ–‡ç»å›é¡§ -> ç™¼æ•£ -> æ”¶æ–‚ -> å±¤ç´šåŒ– -> çŸ©é™£åŒ–ã€æµç¨‹ã€‚

    ã€ä»»å‹™æµç¨‹ã€‘ï¼š
    1. **æ–‡ç»è™•ç†**ï¼šè¾¨è­˜æ–‡ç»ä¸¦ç·¨è™Ÿ (ID 0, 1...)ï¼Œè½‰ç‚º APA æ ¼å¼ã€‚
    2. **Step 1 ç™¼æ•£ (Pooling)**ï¼šæ‰¾å‡ºç´„ {pool_n} å€‹ã€ŒåŸå§‹ç´°é …ã€ï¼Œä¸¦æ¨™è¨˜å‡ºè™• IDã€‚
    3. **Step 2 æ”¶æ–‚ (Convergence)**ï¼šå°‡å…¶æ­¸ç´ç‚º {crit_n} å€‹ã€Œè©•ä¼°æº–å‰‡ (Criteria)ã€ã€‚
    4. **Step 3 å±¤ç´š (Hierarchy)**ï¼šå°‡é€™ {crit_n} å€‹æº–å‰‡ï¼Œæ­¸ç´åˆ†é¡åˆ° {dim_n} å€‹ã€Œè©•ä¼°æ§‹é¢ (Dimensions)ã€ã€‚

    ã€è¼¸å‡º JSON æ ¼å¼ (åš´æ ¼éµå®ˆ)ã€‘ï¼š
    {{
      "papers": [
        {{ "id": 0, "apa": "ä½œè€…A (2024). æ¨™é¡Œ..." }},
        ...
      ],
      "step1_raw_pool": [
        {{ "name": "åŸå§‹ç´°é …åç¨±", "matched_ids": [0, 2] }},
        ... (ç´„ {pool_n} å€‹)
      ],
      "final_hierarchy": [
        {{
          "dimension_name": "æ§‹é¢åç¨± (å¦‚ï¼šè²¡å‹™æ§‹é¢)",
          "contained_criteria": [
             {{
               "criteria_name": "æº–å‰‡åç¨± (å¦‚ï¼šå»ºç½®æˆæœ¬)",
               "source_raw_items": ["åŸå§‹ç´°é …A", "åŸå§‹ç´°é …B"],
               "reasoning": "åˆä½µç†ç”±èªªæ˜...",
               "matched_paper_ids": [0, 2]
             }},
             ...
          ]
        }},
        ... (å…± {dim_n} å€‹æ§‹é¢)
      ]
    }}
    
    æ–‡ç»å…§å®¹ï¼š
    {text[:13000]}
    """
    
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            try:
                res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                match = re.search(r'\{.*\}', res_text, re.DOTALL)
                if match:
                    return "OK", json.loads(match.group(0))
                else:
                    return "ERROR", "JSON è§£æå¤±æ•—ï¼ŒAI å›å‚³æ ¼å¼ä¸ç¬¦ã€‚"
            except:
                return "ERROR", "AI å›å‚³çµæ§‹ç•°å¸¸ã€‚"
        else:
            return "ERROR", f"API Error: {response.status_code}"
    except Exception as e:
        return "ERROR", str(e)

# --- 5. ä¸»ç•«é¢ ---
st.title("ğŸ’ MCDM å…¨åŠŸèƒ½å±¤ç´šåˆ†æå·¥ä½œå€")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»æ‘˜è¦ï¼š", height=250)

if st.button("ğŸš€ åŸ·è¡Œå…¨åŠŸèƒ½åˆ†æ", type="primary"):
    if not api_key:
        st.error("âŒ è«‹æª¢æŸ¥å´é‚Šæ¬„ï¼Œç¢ºèªå·²è¼¸å…¥ API Key æˆ–è¨­å®š Secretsã€‚")
    elif not raw_text:
        st.warning("âš ï¸ è«‹è¼¸å…¥æ–‡ç»è³‡æ–™ï¼")
    else:
        with st.spinner(f"ğŸ” AI æ­£åœ¨åŸ·è¡Œé‹ç®—ï¼šç™¼æ•£({pool_size}) -> æ”¶æ–‚({criteria_size}) -> æ§‹é¢({dim_size})..."):
            valid_model = get_best_model(api_key)
            
            if not valid_model:
                st.error("âŒ æ‰¾ä¸åˆ°å¯ç”¨æ¨¡å‹ï¼Œè«‹ç¢ºèª API Key æ˜¯å¦æœ‰æ•ˆã€‚")
            else:
                status, result = run_full_analysis(raw_text, api_key, valid_model, thesis_topic, pool_size, criteria_size, dim_size)
                
                if status == "OK":
                    st.success("âœ… åˆ†æå®Œæˆï¼æ‰€æœ‰è¡¨æ ¼å·²ç”Ÿæˆã€‚")
                    
                    # --- è³‡æ–™å‰è™•ç† ---
                    papers = result.get("papers", [])
                    raw_pool = result.get("step1_raw_pool", [])
                    hierarchy = result.get("final_hierarchy", [])
                    
                    # å»ºç«‹ä»£è™Ÿå°ç…§ (ID -> A, B, C...)
                    id_to_code = {}
                    legend_rows = []
                    for idx, p in enumerate(papers):
                        code = string.ascii_uppercase[idx % 26]
                        id_to_code[p['id']] = code
                        legend_rows.append({"ä»£è™Ÿ": code, "æ–‡ç»ä¾†æº (APA)": p['apa']})
                    
                    df_legend = pd.DataFrame(legend_rows)
                    
                    # --- å»ºç«‹ 4 å€‹åˆ†é  ---
                    t1, t2, t3, t4 = st.tabs([
                        "1ï¸âƒ£ Step 1: åŸå§‹ç™¼æ•£æ± ", 
                        "2ï¸âƒ£ Step 2&3: å±¤ç´šæ¶æ§‹èˆ‡æ”¶æ–‚", 
                        "3ï¸âƒ£ Step 4: çŸ©é™£åˆ†æåœ–", 
                        "4ï¸âƒ£ æ–‡ç»å°ç…§è¡¨"
                    ])
                    
                    # Tab 1: åŸå§‹æ±  (Raw Pool)
                    with t1:
                        if raw_pool:
                            raw_rows = []
                            for i, item in enumerate(raw_pool):
                                ids = item.get("matched_ids", [])
                                codes = sorted([id_to_code.get(pid, "?") for pid in ids])
                                raw_rows.append({
                                    "åºè™Ÿ": i + 1,
                                    "åŸå§‹ç´°é …æº–å‰‡": item.get("name"),
                                    "å‡ºè™•ä»£è™Ÿ": ", ".join(codes)
                                })
                            st.subheader(f"Step 1: åŸå§‹æ–‡ç»ç¯©é¸ (å…± {len(raw_rows)} é …)")
                            st.dataframe(pd.DataFrame(raw_rows), hide_index=True, use_container_width=True)
                        else:
                            st.warning("ç„¡è³‡æ–™")

                    # Tab 2: å±¤ç´šæ¶æ§‹ (Hierarchy)
                    with t2:
                        hier_rows = []
                        for dim in hierarchy:
                            dim_name = dim.get("dimension_name")
                            criteria_list = dim.get("contained_criteria", [])
                            
                            for crit in criteria_list:
                                ids = crit.get("matched_paper_ids", [])
                                codes = sorted([id_to_code.get(pid, "?") for pid in ids])
                                
                                hier_rows.append({
                                    "å±¤ç´šä¸€ï¼šæ§‹é¢": dim_name,
                                    "å±¤ç´šäºŒï¼šæº–å‰‡": crit.get("criteria_name"),
                                    "æ¶µè“‹ä¹‹åŸå§‹ç´°é …": ", ".join(crit.get("source_raw_items", [])),
                                    "å‡ºè™•ä»£è™Ÿ": ", ".join(codes),
                                    "æ”¶æ–‚èˆ‡æ­¸ç´ç†ç”±": crit.get("reasoning")
                                })
                        
                        st.subheader("Step 2 & 3: æº–å‰‡æ”¶æ–‚èˆ‡å±¤ç´šæ¶æ§‹")
                        st.dataframe(pd.DataFrame(hier_rows), hide_index=True, use_container_width=True)

                    # Tab 3: çŸ©é™£åœ– (Matrix)
                    with t3:
                        matrix_rows = []
                        all_codes = [d["ä»£è™Ÿ"] for d in legend_rows]
                        
                        # ä½¿ç”¨å±¤ç´šè¡¨çš„è³‡æ–™ä¾†å»ºç«‹çŸ©é™£
                        for row_data in hier_rows:
                            m_row = {
                                "æ§‹é¢": row_data["å±¤ç´šä¸€ï¼šæ§‹é¢"],
                                "æº–å‰‡": row_data["å±¤ç´šäºŒï¼šæº–å‰‡"]
                            }
                            # å¡«å…¥é»‘é»
                            source_codes = row_data["å‡ºè™•ä»£è™Ÿ"].split(", ")
                            for code in all_codes:
                                m_row[code] = "â—" if code in source_codes else ""
                            
                            matrix_rows.append(m_row)
                            
                        st.subheader("Step 4: æº–å‰‡ vs æ–‡ç» çŸ©é™£åœ–")
                        st.dataframe(pd.DataFrame(matrix_rows), hide_index=True, use_container_width=True)

                    # Tab 4: å°ç…§è¡¨ (Legend)
                    with t4:
                        st.subheader("æ–‡ç»ä»£è™Ÿå°ç…§è¡¨")
                        st.dataframe(df_legend, hide_index=True, use_container_width=True)
                        
                    # --- å…¨è¡¨æ ¼ä¸‹è¼‰ ---
                    st.divider()
                    output = BytesIO()
                    try:
                        import xlsxwriter
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            if raw_pool: pd.DataFrame(raw_rows).to_excel(writer, sheet_name='1_åŸå§‹ç™¼æ•£æ± ', index=False)
                            pd.DataFrame(hier_rows).to_excel(writer, sheet_name='2_å±¤ç´šèˆ‡æ”¶æ–‚', index=False)
                            pd.DataFrame(matrix_rows).to_excel(writer, sheet_name='3_åˆ†æçŸ©é™£', index=False)
                            df_legend.to_excel(writer, sheet_name='4_æ–‡ç»å°ç…§', index=False)
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Excel å ±å‘Š (å«æ‰€æœ‰è¡¨æ ¼)",
                            data=output.getvalue(),
                            file_name="MCDM_Full_Analysis.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            type="primary"
                        )
                    except Exception as e:
                        st.error(f"Excel åŒ¯å‡ºæ¨¡çµ„ç™¼ç”ŸéŒ¯èª¤: {e}")

                else:
                    st.error("åˆ†æå¤±æ•—ï¼Œè«‹æŸ¥çœ‹ä¸‹æ–¹éŒ¯èª¤è¨Šæ¯ï¼š")
                    st.code(result)
