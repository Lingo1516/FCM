import streamlit as st
import pandas as pd
import requests
import string
import re
from collections import Counter
from io import BytesIO

# --- å˜—è©¦åŒ¯å…¥å‚™ç”¨å¥—ä»¶ (Jieba) ---
# é€™æ˜¯æœ¬æ©Ÿé‹ç®—çš„é—œéµï¼Œè¬ä¸€ Google å¤±æ•—å°±é å®ƒ
try:
    import xlsxwriter
    import jieba
    import jieba.analyse
except ImportError:
    pass

st.set_page_config(page_title="å…¨è‡ªå‹•è£œä½åˆ†æå™¨", layout="wide", page_icon="ğŸ›¡ï¸")

# ==========================================
# ğŸ›‘ å·¦å´è¨­å®šå€
# ==========================================
with st.sidebar:
    st.header("ğŸ›¡ï¸ è¨­å®š")
    st.info("æ­¤ç‰ˆæœ¬ç‚ºã€Œä¸æ­»é³¥ã€æ¨¡å¼ï¼šè‹¥ Google é€£ç·šå¤±æ•—ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ‡æ›è‡³æœ¬æ©Ÿé‹ç®—ï¼Œç¢ºä¿æ‚¨ä¸€å®šèƒ½æ‹¿åˆ°çµæœã€‚")
    
    # è®“ä½¿ç”¨è€…è¼¸å…¥ Key
    user_key = st.text_input("Google API Key (é¸å¡«)", type="password")
    
    # é è¨­å‚™ç”¨ Key (èˆŠçš„ï¼Œé›–å¯èƒ½å·²æ»¿ä½†å‚™è‘—)
    DEFAULT_KEY = "AIzaSyBlj24gBVr3RJhkukS9p6yo5s2-WVBH2H0"
    target_key = user_key if user_key else DEFAULT_KEY

# ==========================================
# ğŸ‘‰ ä¸»ç•«é¢
# ==========================================
st.title("ğŸ“„ æ–‡ç»åˆ†æå·¥ä½œå€ (ä¿è­‰ç”¢å‡ºç‰ˆ)")

raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç»è³‡æ–™ (æ¯ç¯‡è«‹æ›è¡Œ)ï¼š", height=300)

# --- 1. æœ¬æ©Ÿæ¼”ç®—æ³• (Jieba) - é€™æ˜¯æœ€å¼·çš„å‚™èƒ ---
def run_local_jieba(text):
    # å¦‚æœæœ‰è£ jieba å°±ç”¨ jiebaï¼Œæ²’è£å°±ç”¨ç°¡å–®çµ±è¨ˆ
    try:
        tags = jieba.analyse.extract_tags(text, topK=15, allowPOS=('n', 'vn', 'v'))
        return tags
    except:
        # æœ€ç°¡é™‹çš„æ–·è© (æ¯å…©å€‹å­—åˆ‡ä¸€åˆ€)ï¼Œä¿è­‰ä¸å ±éŒ¯
        clean = re.sub(r'[^\u4e00-\u9fa5]', '', text)
        words = [clean[i:i+2] for i in range(len(clean)-1)]
        return [w for w, c in Counter(words).most_common(15)]

# --- 2. Google AI æ¼”ç®—æ³• ---
def run_google_ai(text, key):
    # å˜—è©¦åˆ—è¡¨ï¼Œå“ªå€‹èƒ½é€šå°±ç”¨å“ªå€‹
    models_to_try = ["gemini-1.5-flash", "gemini-1.0-pro", "gemini-pro"]
    
    for model in models_to_try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={key}"
        headers = {'Content-Type': 'application/json'}
        prompt = f"æ­¸ç´10å€‹å­¸è¡“æ§‹é¢åè©ï¼Œç”¨é “è™Ÿéš”é–‹ã€‚æ’é™¤ç„¡é—œè©(æ—¥æœŸã€ä¸‹åˆ)ï¼š{text[:5000]}"
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            # è¨­å®š 3 ç§’è¶…æ™‚ï¼Œä¸è¡Œå°±æ›ä¸‹ä¸€å€‹
            response = requests.post(url, headers=headers, json=data, timeout=3)
            if response.status_code == 200:
                res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                return "SUCCESS", res_text
            elif response.status_code == 429:
                continue # é€™å€‹æ»¿äº†ï¼Œè©¦ä¸‹ä¸€å€‹
            elif response.status_code == 404:
                continue # é€™å€‹æ‰¾ä¸åˆ°ï¼Œè©¦ä¸‹ä¸€å€‹
        except:
            continue
            
    return "FAIL", None

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def parse_text(text):
    lines = text.strip().split('\n')
    return [{"title": line[:15], "content": line} for line in lines if len(line) > 5]

# --- åŸ·è¡ŒæŒ‰éˆ• ---
if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè¼¸å…¥è³‡æ–™ï¼")
    else:
        status_box = st.empty()
        status_box.info("ğŸ¤– æ­£åœ¨å˜—è©¦é€£ç·š Google AI...")
        
        # 1. å…ˆè©¦ Google
        status, ai_result = run_google_ai(raw_text, target_key)
        
        final_keywords = []
        used_source = ""
        
        if status == "SUCCESS":
            status_box.success("âœ… Google AI åˆ†ææˆåŠŸï¼")
            final_keywords = [k.strip() for k in ai_result.replace("\n", "ã€").split("ã€") if k.strip()]
            used_source = "Google AI"
        else:
            # 2. Google å¤±æ•—ï¼Œè‡ªå‹•åˆ‡æ›æœ¬æ©Ÿ
            status_box.warning("âš ï¸ Google é€£ç·šç•°å¸¸ (404/429)ï¼Œå·²è‡ªå‹•åˆ‡æ›è‡³ã€Œæœ¬æ©Ÿæ¼”ç®—æ³•ã€å®Œæˆåˆ†æã€‚")
            final_keywords = run_local_jieba(raw_text)
            used_source = "æœ¬æ©Ÿæ¼”ç®—æ³• (Jieba)"
            
        # --- 3. ç”¢å‡ºçµæœ (çµ•å°æœƒåŸ·è¡Œåˆ°é€™è£¡) ---
        st.divider()
        st.caption(f"æœ¬æ¬¡åˆ†æä½¿ç”¨æ ¸å¿ƒï¼š{used_source}")
        
        if final_keywords:
            selected_keywords = st.multiselect("åˆ†ææº–å‰‡", options=final_keywords, default=final_keywords)
            
            if selected_keywords:
                lit_data = parse_text(raw_text)
                matrix = {}
                labels = []
                titles = []
                
                for i, item in enumerate(lit_data):
                    lbl = string.ascii_uppercase[i % 26]
                    labels.append(lbl)
                    titles.append(item['title'])
                    matrix[lbl] = ["â—‹" if k in item['content'] else "" for k in selected_keywords]
                
                df = pd.DataFrame(matrix, index=selected_keywords)
                df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "æ–‡ç»": titles})
                
                c1, c2 = st.columns([2, 1])
                with c1: st.dataframe(df, use_container_width=True)
                with c2: st.dataframe(df_legend, hide_index=True)
                
                output = BytesIO()
                try:
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, sheet_name='çŸ©é™£')
                        df_legend.to_excel(writer, sheet_name='å°ç…§è¡¨')
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "analysis.xlsx")
                except:
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", df.to_csv().encode('utf-8-sig'), "analysis.csv")
