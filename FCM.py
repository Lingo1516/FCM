import streamlit as st
import pandas as pd
import re
import string
from collections import Counter
from io import BytesIO

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="å…å®‰è£å…¨è‡ªå‹•åˆ†æå™¨", layout="wide", page_icon="âš¡")

st.title("âš¡ å…å®‰è£ãƒ»å…¨è‡ªå‹•æ–‡ç»åˆ†æå™¨")
st.markdown("### ä¸éœ€å®‰è£ jiebaï¼Œç›´æ¥ä½¿ç”¨åŸç”Ÿ Python é‹ç®—")

# --- è¼¸å…¥å€ ---
raw_text = st.text_area("ğŸ‘‰ è«‹è²¼ä¸Šäº‚äº‚çš„æ–‡ç»è³‡æ–™ï¼š", height=300, placeholder="ç›´æ¥æŠŠæ‘˜è¦å…¨éƒ¨è²¼é€²ä¾†...")

# --- æ ¸å¿ƒé‚è¼¯ï¼šæ‰‹åˆ»ä¸€å€‹ç°¡å–®çš„æ–·è©å™¨ ---
def simple_keyword_extraction(text, top_n=20):
    # 1. åªä¿ç•™ä¸­æ–‡å­— (éæ¿¾æ‰æ¨™é»ç¬¦è™Ÿå’Œè‹±æ–‡)
    # é€™æ˜¯ç‚ºäº†è®“çµ±è¨ˆæ›´æº–ç¢º
    chinese_only = re.sub(r'[^\u4e00-\u9fa5]', ' ', text)
    
    # 2. å»ºç«‹ n-gram (é›™å­—è©èˆ‡ä¸‰å­—è©)
    # å› ç‚ºæˆ‘å€‘æ²’æœ‰ jiebaï¼Œæ‰€ä»¥æˆ‘å€‘å‡è¨­ã€Œå…©å€‹å­—ã€æˆ–ã€Œä¸‰å€‹å­—ã€é€£åœ¨ä¸€èµ·å‡ºç¾æœ€å¤šæ¬¡çš„ï¼Œå°±æ˜¯é—œéµå­—
    words = []
    content = chinese_only.split()
    
    # å®šç¾©ä¸€äº›å»¢è©± (Stopwords)ï¼Œä¸è¦è®“å®ƒå€‘è®Šæˆé—œéµå­—
    stopwords = set(['ç ”ç©¶', 'æœ¬ç ”ç©¶', 'åˆ†æ', 'æ¢è¨', 'çµæœ', 'é¡¯ç¤º', 'ç™¼ç¾', 'æå‡º', 'èªç‚º', 'ä½¿ç”¨', 'é€²è¡Œ', 'å½±éŸ¿', 'æˆ‘å€‘', 'é€™äº›', 'ä¸åŒ', 'ä»¥åŠ', 'é€é', 'å°æ–¼'])

    for part in content:
        if len(part) < 2: continue
        
        # æŠ“å– 2 å€‹å­—çš„è© (Bigrams)
        for i in range(len(part) - 1):
            w = part[i:i+2]
            if w not in stopwords: words.append(w)
            
        # æŠ“å– 3 å€‹å­—çš„è© (Trigrams) - æ¬Šé‡é«˜ä¸€é»
        for i in range(len(part) - 2):
            w = part[i:i+3]
            if w not in stopwords: words.append(w)
            
    # 3. çµ±è¨ˆå‡ºç¾é »ç‡æœ€é«˜çš„è©
    counter = Counter(words)
    most_common = [w for w, c in counter.most_common(top_n)]
    
    return most_common

# --- è§£ææ–‡ç»çµæ§‹ ---
def parse_literature(text):
    # æŠ“å¹´ä»½ (20xx)
    pattern = r'([^\n\rã€‚]+?[\(\[\{](?:19|20)\d{2}[\)\]\}])'
    segments = re.split(pattern, text)
    
    literature_list = []
    current_author = None
    all_content_for_analysis = ""
    
    for segment in segments:
        segment = segment.strip()
        if not segment: continue
        
        if re.search(r'[\(\[\{](?:19|20)\d{2}[\)\]\}]', segment):
            current_author = segment[-50:]
        else:
            if current_author:
                literature_list.append({"author": current_author, "abstract": segment})
                all_content_for_analysis += segment + "\n"
                
    return literature_list, all_content_for_analysis

# --- åŸ·è¡ŒæŒ‰éˆ• ---
if st.button("ğŸš€ è‡ªå‹•åˆ†æ (å…å®‰è£ç‰ˆ)", type="primary"):
    if not raw_text:
        st.warning("è«‹å…ˆè²¼ä¸Šè³‡æ–™ï¼")
    else:
        # 1. è§£æçµæ§‹
        lit_data, full_text = parse_literature(raw_text)
        
        if not lit_data:
            st.error("æ‰¾ä¸åˆ°å¹´ä»½ç‰¹å¾µ (ä¾‹å¦‚: 2023)ï¼Œç„¡æ³•åˆ‡åˆ†æ–‡ç»ã€‚")
        else:
            # 2. åŸ·è¡Œå…å®‰è£çš„é—œéµå­—æŠ“å–
            auto_keywords = simple_keyword_extraction(full_text)
            
            st.success(f"âœ… åˆ†æå®Œæˆï¼ç³»çµ±ç”¨çµ±è¨ˆæ³•æŠ“åˆ°äº† {len(auto_keywords)} å€‹é«˜é »è©ï¼š")
            
            # 3. è®“ä½¿ç”¨è€…ç¯©é¸
            final_keywords = st.multiselect(
                "ç³»çµ±è‡ªå‹•æŠ“åˆ°çš„é—œéµå­— (å¯åˆªé™¤ä¸æº–çš„)",
                options=auto_keywords,
                default=auto_keywords
            )
            
            if final_keywords:
                # 4. ç•«åœ–
                matrix = {}
                labels = []
                authors = []
                
                # ç”Ÿæˆ A, B, C
                def get_label(index):
                    if index < 26: return string.ascii_uppercase[index]
                    else: return f"{string.ascii_uppercase[index // 26 - 1]}{string.ascii_uppercase[index % 26]}"

                for i, item in enumerate(lit_data):
                    label = get_label(i)
                    labels.append(label)
                    authors.append(item['author'])
                    
                    col_res = []
                    for kw in final_keywords:
                        if kw in item['abstract']:
                            col_res.append("â—")
                        else:
                            col_res.append("")
                    matrix[label] = col_res
                
                # é¡¯ç¤ºè¡¨æ ¼
                df_matrix = pd.DataFrame(matrix, index=final_keywords)
                df_legend = pd.DataFrame({"ä»£è™Ÿ": labels, "ä½œè€…": authors})
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.dataframe(df_matrix, use_container_width=True)
                with col2:
                    st.dataframe(df_legend, hide_index=True, use_container_width=True)
                
                # ä¸‹è¼‰
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df_matrix.to_excel(writer, sheet_name='çŸ©é™£')
                    df_legend.to_excel(writer, sheet_name='ä½œè€…')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", output.getvalue(), "no_install_analysis.xlsx")
